## lecture 1 关系模型&关系代数

### 1 数据库

_ 数据库 _ 是对现实世界的某些方面建模的相互关联的数据有组织的集合（例如对学生属于班这个关系建模，对数字音乐商城建模）。人们经常混淆数据库（database）和数据库管理系统（database management system）（例如 MySQL，Oracle，MongoDB），数据库管理系统是一个管理数据库的软件。
设想一个为数字音乐商城（例如 Spotify）建模的数据库，数据库保存艺术家和每个艺术家有哪些专辑的信息。

### 2 平面文件
DBMS 将数据库存在逗号分隔文件（CSV）中，每个实体都被存在于自己的文件中。当应用程序想要去读取或更新记录的时候，它每次都必须去解析文件。每个实体有自己的属性，在每个文件中，不同的记录将被分布在不同的行中，每个记录的每个属性都由逗号分隔。

回到之前数字音乐商店的例子中，它有 2 个文件：一个是艺术家，一个是专辑。一个艺术家可能有名字、出生时间和国家等属性，专辑可能有名字、艺术家、发布时间等属性。

**Issues with Flat File（平面文件的问题）：**

*   **Data Integrity（数据完整性）**

1.  我们如何确保每个专辑的艺术家是相同的？
2.  如果有人在专辑发布时间写了一个非法字符该怎么办？
3.  我们如何在一个专辑中存多个艺术家？

*   **Implementation（实现）**

1.  我们如何找到一个特定的记录？
2.  如果我们想要创建一个新的应用使用相同的数据库？
3.  如果 2 个线程尝试在相同的时间去写一个相同的文件？

*   **Durability（持久性）**

1.  如果当你的程序正在更新数据的时候机器坏了该怎么办？
2.  如果你为了高可用想对数据库进行分片并部署到不同的机器上该怎么办？

### 3 数据库管理系统（DBMS）

_数据库管理系统（DBMS）_是一个软件，它允许应用程序在数据库中存储和分析信息。

通用的 DBMS 被设计成允许定义，创建，更新和管理数据库。

**早期的 DBMS**

数据库应用程序通常很难构建和维护，因为逻辑层和物理层之间存在紧密的耦合。逻辑层是数据库拥有哪些实体和属性，而物理层是如何存储这些实体和属性。早期，物理层被定义在应用程序的代码中，如果我们想要修改物理层，我们必须修改代码来匹配新的物理层。

### 4 关系模型

Ted Codd 意识到每次更改物理层的时候都要重写 DBMS。因此在 1970 年他提出了关系模型来避免这种情况。其中关系模型有 3 个关键点：

*   用简单的数据结构存储数据（关系）。
*   通过高层语言访问数据。
*   物理存储留待实现。

_数据模型_是描述数据在数据库中的一系列的概念。关系模型是数据模型中的一个例子。

_模式_ 是使用给定数据模型对特定数据集合的描述。

关系数据模型定义了 3 个概念：

*   **Structure（结构）：** 关系的定义及其内容，这是关系拥有的属性以及这些属性可以包含的值。
*   **Integrity（完整）：** 确保数据满足约束条件，一个例子是年份必须为数字。
*   **Manipulation（操纵）：** 如何访问和修改数据。

_关系_一个是无序集合，它代表了实体属性的联系。因为关系是无序的，所以 DBMS 可以以任何方式存储，并允许优化。

_元组_是关系中属性值的集合。最初，值必须是原子或标量，但是现在的值可以是列表甚至是嵌套的数据结构（比如 json）。每个属性都可以是 NULL，它代表这个属性值是未定义的。

一个有 n 个属性的关系称之为_n 维_关系

**Keys（键）**

一个关系的主键唯一定义一个元组。如果你没有定义主键，一些 DBMS 会自动创建一个内部主键。同时大多数 DBMS 支持自动生成 key，所以应用程序无需管理递增主键。
_外键_代表一个关系的一个属性映射到另一个关系的一个属性。

### 5 数据操纵语言（DML）
数据操纵语言（DML）是一种数据库存储数据和检索数据的语言。它分为 2 种类型：
*   **Procedural（程序性的）：** 该查询指定了 DBMS 查找的策略。
*   **Non-Procedural（非程序性的）：** 该查询仅仅指定了需要什么数据而不是如何获取它。

### 6 关系代数

_关系代数_ 是一个在关系中检索和操纵元组基础操作的集合。每个操作以一个或多个关系作为输入，并输出一个新的关系。我们可以组合使用这些关系代数来创建更复杂的查询。

**Select（选择）**

Select 输入 1 个关系，并输出满足特定选择谓词的所有元组。谓词就像一个过滤器，我们可以使用连接词和逻辑词组合多个谓词。
语法： $\sigma _{predicate}(R)$

**Projection（投影）**
Projection 输入 1 个关系，并输出仅包含特定属性的所有元组，你可以在输入关系中重新排列属性的顺序，也可以操纵这些值。
语法： $\pi _{A1,A2,...,An}(R)$

**Union（并集）**
Union 输入 2 个关系并输出 1 个关系，该关系包含至少出现在 1 个关系中的所有元组。注意：2 个输入关系必须拥有相同的属性值。
语法： $(R\cup S)$

**Intersection（交集）**
Intersection 输入 2 个关系并输出 1 个关系，该关系包含同时出现在 2 个关系中的所有元组。注意：2 个输入关系必须拥有相同的属性值。
语法： $(R\cap S)$(

**Difference（差集）**
Difference 输入 2 个关系并输出 1 个关系，该关系包含出现在第 1 个关系中但不出现在第 2 个关系中的所有元组。注意：2 个输入关系必须拥有相同的属性值。
语法： $(R-S)$

**Product（乘积）**
Product 输入 2 个关系并输出 1 个关系，该关系包含输入元组的所有可能组合。
语法： $(R\times S)$

**Join（连接）**
Join 输入 2 个关系并输出 1 个包含所有元组的关系，该元组是 2 个元组的组合，其中对于共享的每个属性，2 个元组的属性值必须相同。
语法： $(R\Join S)$

**Observation（总结）**
关系代数是一种过程语言，他定义了如何查询的高层表示。例如 $\sigma _{b_{id}=102}(R\Join S)$表示首先 join R 和 S 然后进行 select。而 $(R\Join(\sigma _{b_{id}=102}(S)))$ 将会先 select S，然后再进行 join。这 2 个表达式将会产生相同的答案，但是如果 S 是十亿的数据集合中只有一个元组满足 $b_{id}=102$，那么使用 $(R\Join(\sigma _{b_id=102}(S)))$的速度会比 $\sigma _{b_id=102}(R\Join S)$ 快很多。
一个比较好的方式是直接描述你想要的结果，然后 DBMS 会决定如何进行计算。SQL 完全可以做到这点，因为它是在关系模型数据库上编写查询的一种标准。

## Lecture 3 数据库存储（上）

我们关注是面向磁盘的数据库系统（disk-oriented DBMS），这意味着每次进行查询时数据都不在内存中，我们需要从磁盘去获取数据，这就对数据库的设计和机制有了一定的要求：如何防止数据丢失、保存无效、错误数据等。这就涉及到易失性存储（Volatile）和非易失性存储（Non-Volatile）的区别。

![](<assets/1714139888616.png>)

在本门课程中，内存指代 DRAM，磁盘指代 SSD、HDD 或者网络存储（例如云存储）等内容。实际上，现在还存在一种叫非易失性内存的玩意，目前还没有被广泛使用，但是已经存在了，上海交大的陈海波教授就发表过基于非易失性内存设计的事务系统，有幸听过其报告，论文地址 [rdpma-atc21.pdf (sjtu.edu.cn](https://link.zhihu.com/?target=https%3A//ipads.se.sjtu.edu.cn/_media/publications/rdpma-atc21.pdf)

由于系统假设数据全存储在磁盘上，因此 DBMS 的任务就是从磁盘到内存之间来回移动数据，因为系统不能直接对磁盘进行操作。一个数据库系统的目标就是`让上层应用感觉所有的操作都在内存上，即使内存总是远远小于磁盘的。` 磁盘的读写会带来很大的开销，因此一个好的设计应该让 DBMS 在等待磁盘的数据时能够处理其他查询（对内存）。

![](<assets/1714139888772.png>)

上图是面向磁盘的数据库管理系统示意图。数据库中的文件被组织成页（Page），第一页是目录页（Directory，**当然这里其实不知道目录页是啥**）。为了对数据进行操作，DBMS 需要从磁盘取出数据放到内存中，那么内存中就有一个缓冲池（Buffer Pool）来管理磁盘和内存之间数据的来回移动。同时 DBMS 还提供了一个执行引擎来进行查询。引擎向缓冲池请求特定 page，缓冲池负责将请求的 page 放到内存供引擎访问。那么，我们的缓冲池管理器（Buffer Pool Manager）就需要确保执行引擎访问内存时不会缺页。
这种设计从宏观来讲类似于操作系统中的虚拟内存（Virtual Memory）：

那么为什么数据库系统需要自己来管理内存而不是让操作系统来帮我们完成内存管理呢？这基于很多方面的考量：

实现虚拟内存的一种方法是使用 mmap（memory mapping）。通过 mmap 我们可以将文件的内容映射到进程的地址空间，进程在地址空间上读取，操作系统负责在磁盘和内存之间来回移动页面。然而，如果 mmap 遇到 page fault，那么这个进程将会被阻塞（操作系统要将 page 从磁盘 load 到内存）。

当然，如果我们的数据库只需要读取数据的话，使用 mmap 实际上是可行的，但是问题在于我们并不仅仅需要读。如果有写操作，那么操作系统是不知道那些 page 需要在其他 page 执行前从内存刷到磁盘上的，这将会与日志与并发控制的实现有关。

![](<assets/1714139888838.png>)

当然，就如上图所示，我们也可以通过一些指令来指导操作系统进行 page 的替换（madvise, mlock, msync），也还是有数据库完全使用或者部分使用 mmap，例如早期的 MongoDB（但是后来 MongoDB 花大价钱收购了 WiredTiger 作为其默认的存储引擎，可以看到 mmap 还是存在一些问题的）。但总的来说，让 DBMS 自己管理 page 始终会是一个更加高效且安全的做法，这可以更好的支持：

*   Flushing dirty pages to disk in the correct order：将脏页按照正确顺序刷新到磁盘
*   Specialized prefetching：专门的预取规则
*   Buffer replacement policy：缓冲区替换策略
*   Thread/process scheduling：线程与进程的调度

Note: The OS is **not** your friend.

下面我们来看看数据库系统中的存储管理器（Storage Manager）或者说存储引擎（Storage Engine）。

实际上，除了专门定制了文件管理系统的 DBMS（Oracle，DB2 和 SQL server），近年来大多数 DBMS 都是将数据库文件按照特定的格式去编码并作为操作系统中的文件去存储，通过操作系统提供的 API 读写，并由存储引擎去管理和维护。某些高端数据库实际上在文件系统上会有一个 shim 层以允许数据库为特定的读写做一些磁盘调度以替提升性能（操作系统也可以做类似的事情，但是操作系统并不知晓语义），不过本门课程不会涉及。

DBMS 将数据库组织成一个 pages 的集合，一个 page 是一个有固定大小的 block，可以包含元组、元数据、索引、日志记录等。存储引擎将会跟踪我们在这些 page 上所有的读写操作，以及跟踪每个 page 中还有多少空间允许存储新的数据。有些系统会要求它是自包含的，这意味着阅读每个 page 所需的所有信息都记录在 page 上，这使得 page 出错时能尽可能容灾恢复。

大多数 DBMS 中，一个 page 只存储一种类型的数据，例如只存储 tuple，只存储索引等。因此，每个 page 都会被赋予⼀个唯⼀的内部标识符，系统会生成属于 page 的 ID。之后，就会有一个 indirection 层，这是在讨论存储时会被反复提及的内容。indirection 层允许将⼀个 page ID 映射到某个物理位置，即某个文件中的某个位置（类似于一个字典映射，其实就是记录⼀个相对位置，方便文件整体移动后，只要知道整体文件的初始位置，我依然可以通过该相对位置（即 page ID）找到某个文件某个位置的数据所对应的 page）。这样的话，就可以支持磁盘的压缩或者使用另一块磁盘而不改变 page ID。

![](<assets/1714139888898.png>)


### heap file organization
对于硬件的 page 而言，一次只能保证对于 4KB 的写入是原子的，这会对日志与并发产生一定的影响。不同的 DBMS 会用不同的方法管理磁盘文件中的 pages，这里列举一种常见的方法：Heap File Organization。

数据库中的 heap 文件是一个无序的 page 集合，可以随机地把 tuple 数据存在文件里（注意，关系数据库模型中的行无序和列无序性质使得这种随机存储并不会出现问题）。

可以通过 Linked List 或者 Page Directory 的形式将 page 组织成一个 heap。

![](<assets/1714139888983.png>)

由于链表的查询时间复杂度是
$O(n)$的，因此 Page Directory 这种类似 Hash Table 的做法更加值得推荐。Page Directory 的一个问题在于要保持目录和实际 page 信息的同步。考虑一个例子，往某个 page 写入后 page 满了，但是在更新目录前系统崩溃了，重启后就必要重新扫描才能维护信息的一致性。不过如果数据量很大，极端情况下这种一致性将一直无法得到保证，这就需要更多的特殊机制。
### Page
#### page header
![](<assets/1714139889039.png>)
好的，在看完 page 存储的组织形式后，让我们来看看一个 page 的内部结构。如上图所示，每个 page 都有一个 header 来记录 page 的一些 metadata，存储着包括 page 大小、校验和、DBMS 版本、事务可见性（一些数据查询和修改的权限等）和压缩信息等内容（这里可以看到，存储的信息可以被进一步压缩）。我们需要根据 Header 的信息来解析 page 中存储的数据。一般来说，page 中数据的存储可以有 2 种常见的方式，分别是
#### 数据存储方式
*   Tuple-oriented 面向元组型
*   Log-structured 日志结构型
![](<assets/1714139889097.png>)
首先来看看面向元组型的存储。上图所示的是一种朴素的做法，类似数组的方式去存储，header 维护一个数组的信息。但是这样显然会有很多问题，例如删除时产生内存碎片，文件的不连续等等（如果是变长的 tuple 将会有更多问题），tuple 的查找也是一个很大的开销。因此这并不推荐。相对来说，更为常用的是下面的 slotted pages：

![](<assets/1714139889156.png>)
被称为 slotted pages 就来源于 slotted 数组，实际上它也是一种将特定 slot 映射到 page 某个特定偏移量上的数据结构，这样一个元组就是由一个 page id 和 slot id 来唯一定位，并且 tuple 是倒序存储的。这样当然可能会在中间有部分数据的浪费，但是为了支持变长的元素我们不得不这么做。当然，有办法去应对，可以去整理或者压缩。例如在 PostgresSQL 中，我们可以进行一种称为 vaccum 的操作用于整理数据库，可以看作是它的 GC。不过需要注意的是，对于视频这样的大文件，可能这样的存储方式就不是那么合适了。
#### record ids
![](<assets/1714139889233.png>)
那么如上图所示，对于所谓的 Record ID，我们可以有一个更加清晰的认知。OK，那么我们接下来看看一个 Tuple 是怎么样的一个结构。
#### tuple data
![](<assets/1714139889303.png>)

除了我们很熟悉的 header，我们还需要有一个 schema，因为所有的数据实际上在底层都是按照 byte 去存储的。schema 指定了究竟是存储了什么。当然，我们并不需要在每个 tuple 里去记录 schema，因为这些内容都可以存在一个专门的 catalog page 里以减少重复（当然，像 MongoDB 这样的 NoSQL 还是有必要记录每个 bson 的字段的）。关于存储，还有一些范式（Normalized）和反范式（Denormalized）的方法，这些内容过于复杂，这里就暂时没有涉及到了。
#### schema
在数据库中，Schema 是关于数据组织、存储和操作的结构描述。它定义了数据库中的数据表、字段、约束、索引等信息。在关系型数据库中，Schema 是数据库中数据的结构表示。这包括：

数据表的结构：每个表的名称以及表中列的名称、数据类型和约束。
数据表之间的关系：主键、外键等约束信息，描述了不同表之间的关联关系。
数据表中的约束条件：包括唯一约束、非空约束、默认值等。
索引信息：用于加速数据检索的索引结构。

## Lecture 4 数据库存储（下）
### Log-structured
终于到了 Lecture 4，这个章节也是介绍有关数据库存储的内容，但是侧重点与上个章节有所区别。

首先承接下 Lecture 4 的内容，我们知道，在内存中 page 中数据的存储可以有 2 种常见的方式，分别是 Tuple-oriented（面向元组型）与 Log-structured（日志结构型）。上一节中已经介绍了面向元组型的存储，这节我们介绍下日志结构型的存储方式。

![](<assets/1714139889358.png>)
这种存储方式并不存储 page 的元组，而是去存储如何创建以及如何修改 tuple 的信息，也就是存储 log 信息。这样做的好处有很多，首先会想到的是方便回滚，因为用了日志数据结构后回滚只需要删除某些 log 即可完成。但是更重要的是这样做的效率很高，因为顺序读写比随机读写要快得多。

考虑这样的一个场景：要更新 10 个元组，而这 10 个元组的信息存储在 10 个 pages 上，那么我们就要修改 10 个 page 的信息，但是如果是日志结构，就只需要把相关的更新语句存储在 1 个 page 上即可。
![](<assets/1714139889435.png>)

![](<assets/1714139889488.png>)
这种存储在 HDFS 等文件系统得到了应用，但是有一个明显的缺点就是方便写，不方便读。如果想要读取一条 record 的内容，就得从日志反向查找。当然，可以通过索引或者压缩的方式来进行优化。这种做法在 HBase，Cassandra，LevelDB（Google）以及 RocksDB（Facebook，由 LevelDB 魔改，移除了 mmap）中这些比较新的都或多或少得到了应用与改进。现在许多新的分布式数据库都使用这种技术并且使用 Go 实现，例如 CockroachDB 使用了 RocksDB 作为底层的存储引擎。

当然，扯远了，这已经是接近分布式数据库的范畴了。基于课程原因，本门课还是专注于面向 tuple 的存储（2021 的课程多了有关 Log Structure Compaction 的内容，以后有机会填坑）。接下来，我们关注数据如何被表示以及如何被存储在每个 page 中。

### Data Representation 

![](<assets/1714139889550.png>)
从宏观的角度来看，一个元组实际上就是一段字节的序列或者说 byte 的数组，DBMS 的任务就是将那些 bytes 翻译成有意义的属性值。DBMS 的 catalogs 中包含着数据表的 schema 和元组的 layout（类似数据表的说明书）。

![](<assets/1714139889606.png>)
DBMS 中的数据表示有点像计算机组成原理或者系统基础中的内容了，如上述的 PPT 所示。但是在数据库中我们还要关注 NUMERIC 或者 DECIMAL 这样的定点数（因为浮点数对于小数的表示会有精度损失，这在一些银行系统或者太空任务等高精度中是无法忍受的）。当然，定点数的运算速度肯定是慢于浮点数，但是定点数可以带来精确的数字表示。下面我们用 PostgreSQL 与 MySQL 中开源的一段代码作为演示。

![](<assets/1714139889666.png>)

![](<assets/1714139889716.png>)
可以看到，在数据库中，定点数的表示实际上是用数字或者 char 来表示一个又一个的数字，结合符号等内容来进行运算，而不是依赖于 CPU 给我们的浮点运算指令。


![](<assets/1714139889780.png>)
下面我们来讨论一下当要保存的内容太大而无法在单个 page 中容纳时应该如何处理。有 2 种方法可以解决：
1.  Overflow Page：额外的页。把 overflow 的内容额外存放到另外的 page 中，用一个指针指向。这样管理起来就是一些特殊的 page，但是在一些持久性等问题上需要做特别的处理。这对于应用程序是透明的，你并不会知道自己是否使用了 overflow page。
2.  External Value Storage：外部存储。存储在外部文件中。这样实现简单，但是 DBMS 无法提供持久性保证，而且也无法对这些外部文件提供事务隔离能力。
选择什么方式呢，既有经济的考量，也有效率的考虑，工程就是这样的一门学科。

### System Catalogs
![](<assets/1714139889832.png>)
下面我们来看看数据库中的 catalog 的内容。
DBMS 将数据库的元数据存储在内部的 catalog 中，包括表名、索引、视图、用户权限等信息。每个数据库系统都有自己的元数据（或者说 catalog）的获取方法，ANSI 标准做了一些规定，每个数据库都遵循了这些规定，同时也有一些快捷命令（例如`show databases`）例如 mysql 中的 information_schema
![](../../img/Pasted%20image%2020240426231318.png)
### Storage Model
#### database workloads

下面来讲储模型讲存。实际上关系型数据库的模型并没有规定应该如何存储数据，也没有提到任何有关数据和元组的内容。到目前为止，我们可能会认为一个 record 就是一行（row），但是对于某些 wordload 来说这可能不是最好的做法。这就涉及到以行存储与列存储的概念，及 OLTP 与 OLAP 的概念。

![](<assets/1714139889891.png>)

OLTP（On-line Transaction Processing）的思路是，我们从外界拿到数据后，将其放入数据库系统，之后进行简单的查询或者更新。使用 OLTP 系统的一个很典型的例子就是网购商城的购物车，加入购物车，下单，修改信息等等，每次操作都访问部分的 tuple 并且做微小的更新。

OLAP（On-line Analytical Processing）的思路是，在 OLAP 中搜集大量的数据后，想从中分析出一些东西，类似数据科学，挖掘出一些有用的内容。这种情况下，我们不会修改已有的数据，而是分析派生出新的数据，有点类似数据挖掘的概念。某种意义上，OLAP 是只读的，通常会做大量的 join 操作。

![](<assets/1714139889948.png>)

现在也出现了 HTAP（Hybrid Transaction Analytical Processing）这样的新概念，试图一把抓，我全都要。
那么哪种 workload 对应哪种存储模型就是一门很深的学问了。对于行存储，下面我们来谈谈 N-ary 存储模型。
#### n-ary存储模型
N-ary Storage Model（NSM）：基本思想就是`将单个 tuple 的所有属性都顺序放在一个 page 中`，这是有利于 OLTP 的一个存储模型，因为他提供了足够小的存储粒度（内容都是顺序排列的，这样你可以只关心你的数据）

![](<assets/1714139890004.png>)

但是这样的行存储在执行 OLAP 任务时将会是一种灾难，详见下面的图：

![](<assets/1714139890055.png>)
可以看到，在这个查询中，有很多无用的数据，但是由于行存储的原因，我们每次查询时都需要把整个 page 加载进来，这就会带来很大的性能和资源浪费，这也是为什么会有列存储的原因。对于列存储来说，可以仅仅读取某几个属性的值，这样对于 OLAP 将会是很好的支持，具体可见下图，可以很方便地对每个 attribute 字段进行扫描。
#### dsm存储模型
按列进行存储
![](<assets/1714139890106.png>)
这种存储也被称为 Decomposition Storage Model（DSM），这来源于他把每个元组按照字段拆分存储。
下面是这两种存储方式的对比。简单来说，就是 OLTP 用行存储，OLAP 用列存储。

![](<assets/1714139890171.png>)
![](<assets/1714139890235.png>)



## Lecture 5 Buffer Pool 缓存池
这节课的内容关注 Buffer Pool 的原理与实现（以下以缓存池称呼）。前几节课的内容介绍的是一个面向磁盘的 DBMS 存储相关的内容。数据存储在磁盘上，但是对数据的读写需要放在内存中，这是冯诺依曼架构的计算机所需要遵循的原则。而我们需要设计一个 DBMS 使得：

*   其能处理的数据量超出我们拥有的内存大小
*   最小化在磁盘上执行查询带来了低效率问题
*   让所有的操作都好像在内存中执行一般
![](<assets/1714139890297.png>)

我们可以从时间和空间两个角度来看待这个问题。
*   **空间上**：我们应该将 page 写磁盘的哪里。这个操作的目的是保持数据的空间局部性，让经常被访问的数据在物理上存放在接近的位置。
*   **时间上**：我们应该在何时从磁盘将 page 读入内存，又应该在何时将内存中的 page 写入磁盘。
### Buffer Pool Manager 缓冲池管理器

![](<assets/1714139890353.png>)

简单来说，Buffer Pool 就是内存中一块 page 的缓存，执行引擎请求 page（引擎知道对应的数据在哪个 page 中），先去缓冲池中寻找，如果缓冲池中有该 page，则读取。否则缓冲池将执行 page 的置换算法将请求的 page 加载到缓冲池中。这实际上跟操作系统中的 cache 有很大的相似之处。

![](<assets/1714139890405.png>)

Buffer Pool 将 DBM 主动申请（由 OS 分配）的内存分为多个 frame，每个 frame 实际上就是磁盘上的一个 page 的 slot，执行时将会把磁盘上的 page 载入缓存池中的 frame 上。于是就有了 Page Table（页表）的概念。页表实际上就是一个哈希表，用于跟踪缓存池中有哪些 page。我们通过页表和 page id 就可以查看请求的 page 是否在缓存池中。当然，页表还记录一些元数据

*   Dirty Fla修改了g：page 是否被修改过。如果 page 被，那么它就是脏页，脏页要重新写会磁盘后才会持久化。
*   Pin/Reference Counter：page 被引用的计数，是当前使用该 page 或正在查询该 page 的线程数量，这就意味着我们此时不应该将 page 写到磁盘上（也就是常见的 evict），因为我们可能会对其进行更新。

所以，当我们拿到一个 page 并将其放到缓存池中，如果我们不希望 page 在写之前被移除或者写回磁盘，我们可以用锁将 page 固定住。同样的，如果我们查询页表中某个 entry 是空的，并且我们希望加载 page 到缓存池并更新页表时，我们也需要加锁，防止其他的线程对页表进行操作。这就会涉及到数据库世界中锁的概念和细微的区别。
#### locks vs latches

![](<assets/1714139890501.png>)

*   Locks: 更高级的逻辑原语，暴露给开发人员（可以看到此时持有哪些锁）

*   保护数据更高级的逻辑内容，例如元组，表格或者数据库
*   事务运行时持有锁
*   需要考虑回滚（_还是有点疑惑，以后谈并发控制的时候会再做说明_）

*   Latches: 底层的保护原语，可以使用自旋锁

*   保护 DBMS 内部实现时的临界区，包括贡献内存等，协调 DBMS 内部的多线程
*   操作执行时持有锁。例如更新页表某一项时，先申请锁，防止被其他线程修改
*   不需要考虑回滚（如果没申请到锁，就终止操作）
#### page table(页表) vs page directory(页目录表)

![](<assets/1714139890574.png>)

还有一个需要辨析的概念就是 Page Table 页表与 Page Directory 页目录的区别。
实际上搞清楚概念就好。页表只是内存中一个哈希表，并不需要持久化（丢失了重新建立一个就好）。
但是页目录是告诉执行引擎数据在哪个 page 的那个 slot（即 offset）的关键索引，必须要做到持久化，否则就会找不到数据或者无法正确访问。

![](<assets/1714139890639.png>)

关于缓冲池中内存的分配，可以有全局策略与局部策略两种考虑的方向。全局策略为所有活跃的事务分配内存，而局部策略可以为单独的某个特别的查询或事务分配特定的 frames 而不考虑其他并发事务，这可以让特定的事务表现更好，当然全局上可能会有糟糕的表现。大多数 DBMS 都会尽量兼顾全局和局部信息来进行分配。
#### buffer pool optimizations
![](<assets/1714139890695.png>)

简单的缓存池做到上面的内容就够了，但是对于实际的生产其表现远远不够，因此需要对其进行特定的优化，上述图示就展示了一些场景的 Buffer Pool 优化的方法或者场景。

![](<assets/1714139890750.png>)

第一种方法就是 Multiple Buffer Pools（复数缓存池）。

实际上没有规定一个数据库只能有一个 Buffer Pool，我们可以分配多块内存区域以支持多个 Buffer Pool，每个区域可以有自己的页表，并且自己一套 page id 和 frame 的映射关系，这样可以更好地运用局部策略，并且根据不同的类型来分配 page 的置换策略（例如 index 或者 table data），这样也能减少访问缓存池的不同线程之间对于页表锁的争夺。

![](<assets/1714139890804.png>)

第二种方法就是 Pre-Fetching（预取）。这就是一种大胆的猜测（实际上有迹可循）。对于顺序的扫描或者索引的扫描，我们可能会读一大段连续的 page，那么我们可以一次性把许多连续的 page 预存在缓存池中，这样就不用每次只将一个 page 加载进来而是一次性加载，这样可以减轻很多负担。图中展示的是 index-page 的扫描，index-page 按照二叉搜索树的方式去组织。我们如果理解了查询的上下文，就可以通过这个方法加速。

这也是为什么 DBMS 要自己管理内存的原因，DBMS 知道这个操作要做什么，因此可以做对应的优化。

![](<assets/1714139890859.png>)

第三种方法是 Scan Sharing（扫描共享）。核心思想就是利用某个查询从磁盘中读取的数据，并将该数据用于其他查询中。这跟结果缓存（result caching）不一样，结果缓存只是对相同查询的缓存起来，下次执行同样查询的时候就直接把以前的答案给你罢了。

扫描共享允许多个不同的查询共用一个 table 扫描的游标（cursor）。如上图，Q1 和 Q2 两个查询可以共用扫描的游标。同时接着进行扫描。

第四种方法是 Buffer Pool Bypass（跳过 Buffer Pool）。这实际上是一种放弃缓存池直接使用内存轻量级的查询，查询的 page 不需要在内存长期存在，这部分介绍较少，这里也不多介绍。

![](<assets/1714139890919.png>)

然后要介绍的是 DBMS 中的 buffer pool 与 OS 的 page cache 之间的关联。大多数的磁盘操作都是通过调用 OS 提供的 API 来完成的，而一般 OS 的文件系统缓存中也会对 page 进行缓存，这样就会产生 2 份的 page 缓存。是否要对 OS 提供的缓存进行利用就是一种取舍。（后面用了二十几分钟介绍了  PostgreSQL 中使用 OS Cache 的例子）

 ### Buffer Replacement Policies 缓存置换策略

![](<assets/1714139890980.png>)

下面我们来谈谈缓存置换策略。缓存置换策略就是 DBMS 在缓存池满了而又需要加载一个新的 page 时，决定要将哪个页面置换出去的算法。这实际上跟 OS 中的置换算法是同样的道理。考虑一个页面置换算法时，我们通常考虑正确性、准确性、速度以及元数据负荷这四个因素来选择合适的置换算法。

一个最经典的方法就是 LRU 算法（Least-Recently Used）最近最少用算法。对于缓存池中每个 page 维护一个时间戳，时间戳记录着每个 page 最后被访问的时刻。当 DBMS 需要驱逐（evit）一个 page 时，选择时间戳最早的 page 执行驱逐。一般来说我们可以让 page 按照时间戳排序（优先级队列）以减少搜索的时间。

![](<assets/1714139891040.png>)

这里介绍一个 LRU 算法的近似算法叫做 CLOCK。这个算法无需记录每个 page 的时间戳，而是记录每个 page 的标志位。每次访问 page 时，将 page 的标志位设置为 1。所有的 page 被排列成一个环形的结构，每次需要页面置换时，就环形扫描所有 page，如果 page 的标志位为 1，则设置为 0，继续扫描。否则就移除这个 page。这个算法并不是准确的最近最少用，但是其性能是接近的。

但是 LRU 和 CLOCK 算法都会受到 sequential flooding 带来的影响。也就是说在某些特定的 workload 下，我们想移除的 page 是最近被使用的，而非最近最少用的。

![](<assets/1714139891098.png>)

如图是这种情况的一个示意图。Q1 读入 page0，Q2 顺序扫描，读入 page 0, page 1, page2。此时 Q3 继续读 page0，但是 page 0 被 Q2 读入的 page3 置换掉了，Q3 就需要再把 page0 换进去，但是当时应该把 page 1 或者 page2 置换出去比较好，因为 page 0 会被频繁访问。

我们可以有多种办法来解决这个问题：

1.  LRU-K：记录页面最后 k 次访问的时间戳并且计算时间戳的间隔
2.  局部策略：对不同的访问采用不同的内存池
3.  优先级提示：这也是需要一些先验知识。如果例如我们访问的是 index，而 index-page 按照 B + 树或者有组织的形式存储，我们就可以按照这个信息来帮助页面置换信息的判断。
#### dirty pages
![](<assets/1714139891165.png>)

下面来讨论下有关脏页问题。如果缓存池中的 page 被修改了，他就成了脏页。脏页的 evict 需要将脏页的内容先写到磁盘中（为了持久化）才能加载入新的 page，这就带来了 2 次的磁盘 IO。为了减少每次置换的开销，我们可以用一个后台的的线程来向磁盘写入脏页。一旦脏页被写入磁盘，我们可以将其 dirty flag 置为 false，这样他就不是脏页了。不过有一点需要注意的就是，在脏页写入磁盘前，需要先写日志（log record），这对于数据的一致性和 rollback 非常的重要（这也就是所谓的 WAL，Write Ahead Logging）。


## Lecture 6 Hash Tables 哈希表

这节课的内容是是有关哈希表的内容。实际上这应该是属于数据结构的内容，但是由于哈希表在数据库系统中的广泛使用（例如上一节中所介绍的 Page Table），因此专门用了一个专题来讲哈希表。
### Data Structure in DBMS

![](<assets/1714139891221.png>)

数据库系统内部中存在着很多的数据结构，他们可以被用来存储：

*   Internal Meta-Data（内部元数据）：有关数据库状态的一些信息，例如 Page Directory 或 Page Table 来检索对应的 Page 时，就是一个哈希表。
*   Core Data Storage（核心数据存储）：数据库所存储的数据，可以被组织成一个哈希表或者 B + 树或者其他树结果。例如 MySQL 的 innodb 使用 B + 树的叶节点来存储 tuple。
*   Temporary Data Structures（临时数据）：执行查询或者高效计算时临时创建的，例如 join 时创建的哈希表。
*   Table Indexes（表索引）：辅助我们快速查找到某个 tuple，避免顺序检索

![](<assets/1714139891274.png>)

对于这些数据结构的设计应该考虑 2 点

*   Data Origanization：如何在内存 / Page 中组织数据的存储，并且支持快速的读写与增删
*   Concurrency：如果支持多线程环境数据结构的访问，例如对于同一个内存位置的数据，一个线程在写，另一个线程同时在读，就可能会出现问题。并发控制对于后续的事务处理将会是很重要的一个考量。

当然，这节课的重点是哈希表，而且我们只考虑单线程的情况。

### Hash Table 哈希表

![](<assets/1714139891326.png>)

哈希表的一种抽象数据类型，提供无序的关联数组实现的 API。我们可以将任意的 key 映射到对应的 value 上。在哈希表中并没有顺序的说法，也就是说哈希表的 key 是无序的（但是具体实现时，例如树状哈希，还是有一定的顺序）。对于数组形式的哈希，我们用哈希函数来计算给定 key 的哈希值作为偏移量 offset 并以此来检索 value。

对于哈希表，其空间复杂度是

$O(n)$ ，查找的平均复杂度是$O(1)$ ，但是最坏情况下是$O(n)$ 。

![](<assets/1714139891380.png>)

对于一个理想情况下的哈希表，可以视作一个数组。我们知道所有 key 的数量，并且每个 key 都是唯一的，且每个 key 经过哈希函数映射后都会是不同的值。这样就可以做到一个理想的哈希表。然而实际情况下，很难找到一个完美的哈希函数，这就意味着一定会有哈希冲突的产生，因此我们得对哈希冲突进行处理。

![](<assets/1714139891429.png>)

当我们在谈论哈希表时，我们实际上在谈 2 个概念：
1.  Hash Function：key 的映射。如何将一个大的 key 映射到一个相对小的范围，并且要权衡哈希速度与冲突率
2.  Hash Scheme：如何处理哈希冲突。要权衡使用的存储空间与处理冲突时的额外操作。

### Hash Function 哈希函数

![](<assets/1714139891494.png>)

下面我们先来谈谈哈希函数。常见的哈希函数有 SHA-256（加密的），md5（单向散列的）等等，但是在哈希表中的我们关系的是高速度与低碰撞率，我们并不需要加密的性质。上图展示的一些当前常见的哈希函数。

### Static Hash Scheme

静态的 Hash Scheme 下哈希表的大小是固定的，因此当 DBMS 用完哈希表的存储空间后，哈希表需要扩容并且重建（将原来的值全复制过去）。通常来说，新的哈希表大小将会是原哈希表的 2 倍（指数级类似 C++ 中 STL 里 vector 的扩容）。

**方案 1：Linear Probe Hashing**
这个方案如果我没想错的话应该就是所谓的`线性探查法`或者叫开散列的方法（数据结构课残留的记忆）。

![](<assets/1714139891546.png>)

这个是最基础的一种解决哈希冲突的方案，并且一般是最快的。这个方案使用一维数组就可以解决。在这个方案下，如果在 hash(key) 的位置有数据，就直接插入；否则就线性向后探查，直到找到一个可以插入的位置。不过在这个方案中，我们需要在 slot 中存储 key 的值，这样才可以支持查找与删除。

![](<assets/1714139891598.png>)

对于某个 key 的删除，我们不能简单删除。例如这个上图，我们将 C 删除，我们不能简单将数据删除，否则我们执行 D 相关的操作时，就找不到哈希表中的 D，而是会在原来 C 的位置上插入一个新的元素，这样就有问题了。所以我们得对删除操作对特别的处理。有 2 种方案可以处理这种情况，一种是做一个标记（Tombstone 墓碑），一种是做数据的移动。但是一般来说，在实际处理时，数据的移动将会造成很多问题，因为我们一般直接做一个标记，尽管这样会造成部分空间的浪费。

![](<assets/1714139891662.png>)

这里谈谈有关非唯一 key 的处理。在 hash 表中，如果我们想在哈希表中记录相同的 key 不同的 value，可以有 2 种选择。一种选择是给每个 key 的 slot 指向一个专门的 list，另一种方法是存储冗余的元素。实战中一般第二种方法用的多一些。

**方案 2：Robin Hood Hashing**

![](<assets/1714139891718.png>)

Robin 源于英国传说罗宾汉，有一种劫富济贫的意味在，这也是这个算法的思想来源。在简单的线性探查时，遇到冲突会线性探查下去，但是这样可能会造成一种不平衡，就是可能有某个 key 的值的位置距离 hash(key)的位置非常远，这样就要付出很大的代价去查找。 因此我们可以考虑记录下每个 (key,value) 值距离 hash(key)的相对位置，相对位置越大，就越 “贫穷”，就可以从“富有” 的那里“抢夺”slot 以达到一种平衡。

![](<assets/1714139891803.png>)

![](<assets/1714139891919.png>)

上图中 E 的插入会挤占原来 D 的位置，这就是 Robin 算法的思想。但是实际表现中，大多数情况下线性探查法还是强无敌 ，某些情况下 Robin 算法将会有很大的代价。

**方案 3：Cuckoo Hashing**

![](<assets/1714139891974.png>)

这个方法另辟蹊径，相比前面的方法只使用 1 个哈希表，Cuckoo 算法采用多个哈希表（对应多个哈希函数）。这个方法实际上有点空间换时间的意思，这里就不多做介绍。

![](<assets/1714139892025.png>)

上述谈论的 3 种方案都是静态哈希，这就意味着哈希表的大小是固定的，我们必须提前知道我们想要保存的 key 的大概数量，这样才能知道如何分配空间使得其足够容纳并能最小化哈希碰撞。但是现实没有那么理想，一旦超过容量，就要扩容。扩容并非是直接 append 一段内存，一般来说得重建整个哈希表并迁移。当我们谈到分布式数据库时我们还会谈到一致性哈希算法，这个算法无需调整大小（令人期待的算法）。但是对于单机数据库中的哈希表，我们还是得重新构建，这也是动态的哈希所要解决的问题。

### Dynamic Hashing Schemes

动态哈希支持不重建哈希表的情况下对哈希表动态扩容，也是当前用的比较多的哈希表类型。

**方案 1：Chained Hashing**

![](<assets/1714139892074.png>)

这个是 Java 中 HashMap 默认采用的方案。每个 slot 不是存储元素，而是存储一个指向 bucket 组成链表的指针（引用）。这样就可以做到近乎无限的扩容，而且这样很容易实现线程安全，我们只需要对每个 bucket 加上锁就好。

当然，也很容易想到，这样最经典的就是退化到线性的情况，可能所有的的 key 都映射到同一个链表上。

**方案 2：Extendible Hashing**

![](<assets/1714139892161.png>)

在这个方案中，相比于让链表无限增长，我们选择在合适的时间点对 overflow 的 bucket 进行拆分。相比于重建，拆分可以更好利用原有的空间。

如图所示，这个方案中，hash(key) 被映射为一个 01 位串，有一个 global counter，表示按照 hash(key) 的前 k 位作为指针数组的 key。如果满了，就增加这个 counter 的值，这样 hash table 的容量就可以扩容，而我们要重新构建的只是指针数组而非存有内容的数组，这样就会比静态的结构节省很多的代价。

![](<assets/1714139892210.png>)

上图中，我们想插入 C，此时 global counter 的值是 2，我们只看前 2 位，是 10，也就是十进制数字 2，但是此时 2 的那个 bucket 已经满了，所以我们选择扩容，让 global counter 设置为 3，这样他就会被映射到 101，也就是十进制数字 5 的那个 bucket 上，这样就可以在固定 bucket 大小的情况下动态扩容。

这里需要注意的是除了 global counter 还有一个 local counter，他表示的是`对于这个 bucket 实际上只需要看前多少位`，这是因为这个 bucket 还未被扩容，所以可以不用看 global 的那么多位。

**方案 3：Linear Hashing**
![](<assets/1714139892269.png>)
在 Extendible Hashing 中，尽管调整指针数组的代价并不高，但是调整的时候需要对整个数组上锁，这就会成为一种性能的瓶颈，因此我们可以只对溢出的 bucket 进行扩容，这样就不用上一个全局的锁。要实现这个方法也是需要多个哈希函数，或者说同一个哈希函数，多个 seed。

![](<assets/1714139892325.png>)

具体执行的时候还有一个 Splict Pointer 的问题，这个算法背后涉及到一些数学的原理，较为复杂，这里不多赘述，包括删除等更进一步的操作，有兴趣的读者可以参考 Wiki 的讲解

[Linear hashing - Wikipedia](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Linear_hashing)

## Lecture 7 Tree Indexes Part 1

这节课主要是介绍树状的索引。索引是数据库中很常见的概念，可以被用于快速的查找，但是索引并不适合用上节课讲的哈希表存储，因为我们常常是需要按照一定顺序去检索索引指向的内容的，但是哈希表的 key 理论上是无序的，因此我们需要有另外一个有序的支持快速检索的数据结构。树就是一个很适合的数据结构。

![](<assets/1714139892394.png>)

`所谓索引，实际上是数据库中某些属性的副本，他们被按照特定的排序和组织起来以支持快速的检索和更新。`同时，索引和数据库内部的内容应该是逻辑上同步的，对数据库数据（tuple）的修改要能够实时反映到索引中。例如删除某个 tuple 后，按照索引也不应该找到这个 tuple，否则就会返回错误的结果。同时，索引对于程序员应该是透明的，我们操控的是数据库，我们并不关心索引究竟是怎么同步的，但是他必须要有一组同步机制在那里。

![](<assets/1714139892457.png>)

执行具体操作时，如果利用索引找到最好的执行路径，这实际上就是查询优化的问题，这个之后会介绍。对于索引的维护也是一个任务，我们要考虑索引的存储与索引维护的成本，这就又是另一重的取舍。今天我们主要介绍的就是 B + 树（这是一个很经典的数据结构，经典到今天知道我都不大清楚他的细节 Orz）。

### B+ Tree
![](<assets/1714139892520.png>)

B 树实际上是一组特定的数据结构的统称，有 B 树、B + 树、B * 树等等，很多时候他们会被混起来用，但是在数据库系统中，即便某些数据库说他们用的是 B 树，实际上指的也是 B + 树（大多数情况下），这是一个概念的问题。我们今天所谈的 B + 树实际上也跟其 1973 年论文里的定义有所区别。

![](<assets/1714139892575.png>)

B + 树是一类自平衡树，B 实际上就取自于英文单词 Balance。通过将数据按照某种规则组织使得其插入和查找的时间复杂度都是$O(log\ n)$。相比于 B 树，B + 树的优点在于当我们遍历到 B + 树的底部时，我们可以沿着叶子结点进行扫描并且按照顺序查找。B + 树的思想来源于二叉搜索树，不过 B + 树允许一个结点可以有超过 2 个叶结点。它是为了在磁盘上快速检索数据而设计出来的一个至今为止仍然得到广泛运用的数据结构。
![](<assets/1714139892637.png>)

B + 树是一类多（M）路搜索树，它具备如下性质：
*   完美平衡：每个叶节点都有相同的深度$O(log\ n)$。每次修改数据后，都会调整。
*   除了根节点以外的结点都是至少半满的。假设一个结点的 degree 为 M（最多可以有 M 个 pointer，M-1 个 key），则结点上管理的 key 的数量满足上图中的数量关系。这个数量关系实际上也是 B + 树能够满足性质的一大原因之一。
*   每个有 k 个 key 的中间结点都有 k+1 个非空的子节点。
![](<assets/1714139892695.png>)
每个 B + 树的结点都是由一组 key/value 对的数组（注：其实实际实现不会是数组，这个应该都是分别存储的，但是有对应关系我认为），其中：

*   key：来源于我们要建立索引的属性的值
*   value：根据是 Inner Node（非叶子节点）或者 Leaf Node（叶子结点）有不同的选择。
*   Inner Node：结点的指针 node*
*   Leaf Node：具体的数据

对于叶子结点，还会有兄弟指针（Sibling Pointers）相连，这样就可以支持顺序的检索。
![](<assets/1714139892749.png>)

![](<assets/1714139892807.png>)

如上图是一个理想的叶子结点的存储和实际实现中的情况，可以看到实际存储时将 key 和 value 分开存了，这样就可以支持二分搜索以提高检索效率。

![](<assets/1714139892870.png>)
对于叶子结点中存储的数据类型，可以存储 Record Id，然后根据 Record Id 去检索对应的 tuple。也可以直接存储 Tuple 的数据。2 种方案都有对应的数据库实现。

![](<assets/1714139892922.png>)
B 树和 B + 树的主要区别就在于 B 树的 key 不允许重复而且数据可以存储在任何结点，而 B + 树中的 key 可以重复，但是数据只能存储在叶子结点中。`实际上 B 树的性能是高于 B + 树的，但是却很少得到使用，这是因为 B + 树在多线程下的表现好于 B 树。`

### B+ Tree 的插入
![](<assets/1714139892984.png>)

*   找到合适的叶子结点 L
*   按照排序将数据插入 L
*   如果 L 有足够的空间，返回
*   否则，将 L 的 keys 分裂成 L 和一个新的结点 L2
*   将原来 L 的 keys 平均分，找到一个中间位置 split
*   让 key 小于 split 的放在一个节点，大于的放在另一个节点
*   然后将 split 的信息告诉 L 的父节点
这里介绍了一个神仙网站可以可视化 B + 树的算法（实际上还可以可视化很多其他的数据结构）
[B+ Tree Visualization](https://link.zhihu.com/?target=https%3A//www.cs.usfca.edu/~galles/visualization/BPlusTree.html)

![](<assets/1714139893034.png>)

### B+ Tree 的删除

![](<assets/1714139893086.png>)

*   找到要删除元素所在的叶子节点 L，删除对应的 entry
*   如果 L 保持至少半满，返回
*   如果 L 只剩下 M-1 个元素
*   从与 L 有相同父节点的兄弟节点那里借一个元素过来
*   如果能借过来，就借。否则合并 L 与借失败的那个节点
*   如果合并成功了，就必须得对父节点的指针删除一个（指向 L 的或者兄弟节点的）
*   此时如果太满了，就必须得继续拆分。
*   拆分可能会让父节点的 keys 数量小于半满，就必须继续维护，最后可能重构整个树 （Orz 太复杂了）

![](<assets/1714139893134.png>)

这里介绍一下聚簇索引。他保证 page 中的 tuple 按照 primary key 的顺序来排序，这样就可以快速的拿到数据。

### B+Tree 的查找

![](<assets/1714139893203.png>)

使用 B + 树的索引可以提供任意属性的检索，这就比哈希表提供了更为优越的的性能。

![](<assets/1714139893303.png>)

上图所展示的是一个复合键在 B + 树中的检索。B + 树的搜索是一门很大的学问，包含很多的优化和技巧。







