
## 8. 离散型随机变量的常见分布
![](<assets/1713022611636.png>)
### **1) 伯努利分布 \ 两点分布 \ 0-1 分布** $X∼B(1,p)$ 
$P(X=0)=1-p, P(X=1)=p, p∈(0,1)$
### **2) 二项分布（伯努利概型）** $X∼B(n,p)$
$P(X=k)=C_n^k p^k (1-p)^{n-k}, p∈(0,1), k=0,1,…,n$
N 次独立重复的伯努利试验中成功的次数 X 服从二项分布。
### **3) 泊松分布** $X∼P(λ)$
$P(X=k)=\frac{λ^k e^{-λ}}{k!}, λ>0, k=0,1,2,…$ 泊松分布适合于`描述单位时间内随机事件发生的次数的概率分布`。如某一服务设施在一定时间内受到的服务请求的次数，[电话](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E7%2594%25B5%25E8%25AF%259D)[交换机](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E4%25BA%25A4%25E6%258D%25A2%25E6%259C%25BA)接到呼叫的次数、汽车站台的候客人数、机器出现的故障数、[自然灾害](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E8%2587%25AA%25E7%2584%25B6%25E7%2581%25BE%25E5%25AE%25B3)发生的次数、DNA 序列的变异数、放射性原子核的衰变数、[激光](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E9%259B%25B7%25E5%25B0%2584)的光子数分布等等。
### **4) 几何分布** $X∼G(p)$
$P(X=k)=(1-p)^{(k-1)} p, p∈(0,1), k=1,2,…$
首次试验成功所需做的试验次数 X 服从几何分布。
### **5) 超几何分布**

**超几何分布**（Hypergeometric distribution）描述了由有限个对象中抽出 n 个对象，成功抽出 k 次指定种类的对象的概率（**抽出不放回**（without replacement））。

$$P(X=k)=\frac{C_K^k C_{N-K}^{n-k}}{C_N^n },0<k<min{K,n}$$

![](<assets/1713022611698.png>)
## 9. 连续型随机变量的常见分布

![](<assets/1713022611747.png>)

### **1) 均匀分布** $X∼U(a,b)$ 

![](<assets/1713022611797.png>)
### **2) 指数分布** $X∼E(λ)$

![](<assets/1713022611849.png>)
### **3) 正态分布 \ 高斯分布** $X∼N(μ,σ^2)$

$$f(x)=\frac{1}{√2π σ} e^{-\frac{(x-μ)^2}{2σ^2}}, -∞<x<∞$$
特别地，当 $μ=0, σ=1$ 时为标准正态分布, $X∼N(0,1)$
![](<assets/1713022611905.png>)


### **2) 方差**
方差是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中`方差用来度量随机变量和其数学期望（即均值）之间的偏离程度`。统计中的方差（样本方差）`是每个样本值与全体样本值的平均数之差的平方值的平均数`。在许多实际问题中，研究方差即偏离程度有着重要意义。
方差是**衡量源数据和期望值相差的度量值**。
$D(X)=E((X-E(X))^2)=E(X^2)-E^2(X)$（平方的期望 - 期望的平方）

## 12. 相关系数、协方差

### **1) 协方差**
协方差和相关系数都是用来衡量两个随机变量之间关系强度的统计量，它们在数据分析和统计学中经常被用来描述变量之间的关联程度。
期望值分别为 E[X] 与 E[Y] 的两个实随机变量 X 与 Y 之间的协方差 Cov(X,Y) 定义为：
![](<assets/1713022612003.png>)
即：X, Y 的协方差等于每一个 X 减去 X 平均值乘上每一个 Y 减去 Y 平均值的乘积的和的平均数。
从数值来看，协方差的数值越大，两个变量同向程度也就越大。反之亦然。
从直观上来看，协方差表示的是两个变量总体误差的期望。

如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值时另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值；如果两个变量的变化趋势相反，即其中一个变量大于自身的期望值时另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。

### **2) 相关系数**

定义
$$ \rho_{XY} = \frac{\text{cov}(X, Y)}{\sigma_X \sigma_Y}$$ 
称为随机变量 X 和 Y 的 (Pearson) 相关系数。
即：用 X、Y 的协方差除以 X 的标准差和 Y 的标准差。

* 性质：相关系数的取值范围在 -1 到 1 之间，当相关系数接近 1 时，表示变量之间具有强正相关性；当相关系数接近 -1 时，表示变量之间具有强负相关性；当相关系数接近 0 时，表示变量之间没有线性相关性。
* 意义：相关系数度量了两个变量之间的线性关系的强度和方向。它提供了一种标准化的方法，可以比较不同数据集之间的相关性，以及不同变量之间的相关性。

相关系数也可以看成协方差：一种剔除了两个变量量纲影响、标准化后的特殊协方差。它消除了两个变量变化幅度的影响，而只是单纯反应两个变量每单位变化时的相似程度。
### **3) 相关系数或协方差为 0 的时候能否说明两个分布无关？为什么？**
只能说明`不线性相关，不能说明无关`。因为在数学期望存在的情况下，独立必不相关，不相关未必独立。
## 19. 最大似然估计（极大似然估计）是什么？

极大似然估计就是一种参数估计方法。
最大似然估计的目的是：**利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值**。

原理：极大似然估计是建立在极大似然原理的基础上的一个统计方法，是概率论在统计学中的应用。极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。通过若干次试验，观察其结果，利用试验结果得到某个参数值能够使样本出现的概率为最大，则称为极大似然估计。

方程的解只是一个估计值，只有在样本数趋于无限多的时候，它才会接近于真实值。
*   求最大似然估计量 $\widehat \theta$ 的一般步骤：
```
[1]   写出似然函数；
[2]   对似然函数取对数，并整理；
[3]   求导数；
[4]   解似然方程。
```
*   最大似然估计的特点：
```
[1]   比其他估计方法更加简单；
[2]   收敛性：无偏或者渐近无偏，当样本数目增加时，收敛性质会更好；
[3]   如果假设的类条件概率模型正确，则通常能获得较好的结果。但如果假设模型出现偏差，将导致非常差的估计结果
```

