# 机器学习
https://blog.csdn.net/qq_40506723/article/details/121741662

https://blog.csdn.net/qq_36816848/article/details/115601672

每一节都有

https://blog.csdn.net/weixin_45666566/article/details/106455782

# 深度学习


## 一眼看懂深度学习
https://blog.csdn.net/weixin_43612023/article/details/97235212?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522171262281016800182757932%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=171262281016800182757932&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-97235212-null-null.142^v100^pc_search_result_base1&utm_term=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&spm=1018.2226.3001.4187

## 知识点总结
https://blog.csdn.net/qq_36816848/article/details/122286610?ops_request_misc=%257B%2522request%255Fid%2522%2  能不能53A%2522171262281016800182757932%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=171262281016800182757932&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-122286610-null-null.142^v100^pc_search_result_base1&utm_term=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&spm=1018.2226.3001.4187

### RMSprop 优化器

### Momentum 动量梯度下降
Momentum 主要引入了`基于梯度的移动指数加权平均`的思想，即当前的参数更新方向不仅与当前的梯度有关，也受历史的加权平均梯度影响。对于梯度指向相同方向的维度，动量会积累并增加，而对于梯度改变方向的维度，动量会减少更新。这也就使得收敛速度加快，同时又不至于摆动幅度太大。

### Adam
### 深度学习最全优化方法总结比较（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam）
https://zhuanlan.zhihu.com/p/22252270

# 面试题
https://blog.csdn.net/qq_30057549/article/details/107759723


# 西瓜书读书笔记
https://www.cnblogs.com/limitlessun/p/8505647.html#_label2
https://zhuanlan.zhihu.com/p/134089340

公式推导：
https://datawhalechina.github.io/pumpkin-book/#/

课后习题：
https://zhuanlan.zhihu.com/c_1013850291887845376

# 统计学习方法笔记
https://www.cnblogs.com/limitlessun/p/8611103.html#_label0
https://zhuanlan.zhihu.com/p/36378498

