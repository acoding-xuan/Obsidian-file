# æ–°æŠ€æœ¯æ¨¡å—
## wandb
Weights & Biasesï¼ˆç®€ç§°wandbï¼‰æ˜¯ä¸€ä¸ªç”¨äºæœºå™¨å­¦ä¹ å®éªŒè·Ÿè¸ªå’Œå¯è§†åŒ–çš„å·¥å…·å’Œå¹³å°ã€‚å®ƒæä¾›äº†ä¸€ä¸ªç®€å•çš„Python APIï¼Œå¯ä»¥è½»æ¾åœ°å°†å®éªŒæ•°æ®å‘é€åˆ°äº‘ç«¯ï¼Œå¹¶é€šè¿‡ç½‘ç»œåº”ç”¨ç¨‹åºè¿›è¡Œè®¿é—®å’Œå¯è§†åŒ–ã€‚ä»¥ä¸‹æ˜¯wandbçš„ä¸€äº›æ ¸å¿ƒåŠŸèƒ½ï¼š

1. **å®éªŒè·Ÿè¸ªå’Œè®°å½•**ï¼šwandbèƒ½å¤Ÿè‡ªåŠ¨è·Ÿè¸ªæœºå™¨å­¦ä¹ å®éªŒï¼ŒåŒ…æ‹¬è¶…å‚æ•°ã€æŒ‡æ ‡ã€æ¨¡å‹æ¶æ„ç­‰ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯ä¿å­˜åœ¨äº‘ç«¯ï¼Œä»¥ä¾¿åç»­æŸ¥çœ‹å’Œæ¯”è¾ƒ ã€‚

2. **ç»“æœå¯è§†åŒ–**ï¼šæä¾›äº†ä¸°å¯Œçš„å¯è§†åŒ–åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ›²çº¿å›¾ã€æ•£ç‚¹å›¾ã€ç›´æ–¹å›¾ç­‰ï¼Œå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å®éªŒç»“æœå’Œæ¨¡å‹æ€§èƒ½ ã€‚

3. **æ¨¡å‹æ£€æŸ¥ç‚¹å’Œç‰ˆæœ¬æ§åˆ¶**ï¼šå¯ä»¥ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œå¹¶ç”Ÿæˆå”¯ä¸€çš„ç‰ˆæœ¬å·ï¼Œæ–¹ä¾¿å›æº¯å’Œæ¯”è¾ƒä¸åŒçš„å®éªŒç»“æœ ã€‚

4. **åä½œå’Œå…±äº«**ï¼šé‚€è¯·å›¢é˜Ÿæˆå‘˜å‚ä¸å®éªŒã€æŸ¥çœ‹ç»“æœï¼Œå¹¶è¿›è¡Œè®¨è®ºå’Œåé¦ˆã€‚å…è®¸å°†å®éªŒå’Œç»“æœä¸å…¶ä»–äººå…±äº«ï¼Œä½¿ä»–ä»¬å¯ä»¥åœ¨ä¸åŒçš„ç¯å¢ƒä¸­é‡ç°å’Œä½¿ç”¨æ‚¨çš„å·¥ä½œ ã€‚

5. **é›†æˆå¤šç§æ¡†æ¶**ï¼šæ”¯æŒä¸å„ç§æœºå™¨å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚TensorFlowã€PyTorchã€Kerasç­‰ï¼‰å’Œæœºå™¨å­¦ä¹ å·¥å…·ï¼ˆå¦‚scikit-learnï¼‰é›†æˆï¼Œå¹¶æä¾›äº†æ–¹ä¾¿çš„APIï¼Œæ–¹ä¾¿è¿›è¡Œå®éªŒç®¡ç†å’Œç»“æœè·Ÿè¸ª ã€‚

ä½¿ç”¨wandbæ—¶ï¼Œå¯ä»¥é€šè¿‡å‡ è¡Œä»£ç å¿«é€Ÿé›†æˆåˆ°ç°æœ‰é¡¹ç›®ä¸­ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨`wandb.init()`åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„å®éªŒï¼Œä½¿ç”¨`wandb.log()`è®°å½•å®éªŒä¸­çš„æŒ‡æ ‡å’Œæ—¥å¿—ä¿¡æ¯ï¼Œä½¿ç”¨`wandb.finish()`ç»“æŸå®éªŒè®°å½•ã€‚æ­¤å¤–ï¼Œwandbè¿˜æ”¯æŒæ¨¡å‹çš„ç›‘è§†ï¼ˆ`wandb.watch()`ï¼‰ã€æ–‡ä»¶ä¿å­˜ï¼ˆ`wandb.save()`ï¼‰å’Œä»äº‘ç«¯æ¢å¤å®éªŒè®°å½•çš„æ¨¡å‹å‚æ•°æˆ–æ–‡ä»¶ï¼ˆ`wandb.restore`ï¼‰ç­‰åŠŸèƒ½ ã€‚

## tokenizer
åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å’Œæœºå™¨å­¦ä¹ ä¸­ï¼Œtokenizerï¼ˆåˆ†è¯å™¨ï¼‰æ˜¯ä¸€ä¸ªå…³é”®ç»„ä»¶ï¼Œå®ƒçš„ä¸»è¦ä½œç”¨æ˜¯å°†æ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£å’Œå¤„ç†çš„æ ¼å¼ã€‚
# ä¸æ¸…æ¥šå‚æ•°

## cutoff-len
cutoff_lenå‚æ•°é€šå¸¸ç”¨äºå®šä¹‰å¤„ç†æˆ–è€ƒè™‘åºåˆ—æ•°æ®ï¼ˆå¦‚æ–‡æœ¬ï¼‰æ—¶çš„æœ€å¤§é•¿åº¦ã€‚
## micro_batch_size
åœ¨æä¾›çš„ä»£ç ç‰‡æ®µä¸­ï¼Œmicro_batch_sizeè¢«ç”¨ä½œtransformers.Trainerçš„å‚æ•°ä¹‹ä¸€ï¼ŒæŒ‡å®šäº†åœ¨è®­ç»ƒå’Œè¯„ä¼°è¿‡ç¨‹ä¸­ï¼Œæ¯æ¬¡è¿­ä»£ä½¿ç”¨çš„æ ·æœ¬æ•°é‡ã€‚æ­¤å¤–ï¼Œä»£ç ä¸­è¿˜è®¡ç®—äº†gradient_accumulation_stepsï¼Œè¿™æ˜¯åŸºäºbatch_sizeå’Œmicro_batch_sizeçš„æ¯”ä¾‹æ¥ç¡®å®šçš„ã€‚è¿™æ„å‘³ç€ï¼Œå³ä½¿æ¯æ¬¡åªå¤„ç†å°‘é‡æ ·æœ¬ï¼Œé€šè¿‡æ¢¯åº¦ç´¯ç§¯ï¼Œæ¨¡å‹ä»ç„¶å¯ä»¥æ¨¡æ‹Ÿè¾ƒå¤§æ‰¹æ¬¡å¤§å°çš„è®­ç»ƒæ•ˆæœã€‚
## resume_from_checkpoint
æ¢å¤ä¸­æ–­çš„è®­ç»ƒï¼šå¦‚æœè®­ç»ƒè¿‡ç¨‹ç”±äºæŸäº›åŸå› ï¼ˆå¦‚ç¡¬ä»¶æ•…éšœã€ç”µæºä¸­æ–­ç­‰ï¼‰è¢«æ„å¤–ä¸­æ–­ï¼Œå¯ä»¥ä½¿ç”¨æœ€åä¸€ä¸ªæ£€æŸ¥ç‚¹ä»ä¸­æ–­çš„åœ°æ–¹ç»§ç»­è®­ç»ƒï¼Œè€Œä¸æ˜¯ä»å¤´å¼€å§‹ã€‚

å°è¯•ä¸åŒçš„è®­ç»ƒå‚æ•°ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å­¦ä¹ ç‡ã€ä¼˜åŒ–å™¨æˆ–å…¶ä»–è¶…å‚æ•°ã€‚ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒå¯ä»¥ç¡®ä¿è¿™äº›æ›´æ”¹ä»…å½±å“è®­ç»ƒè¿‡ç¨‹çš„è¿™ä¸€éƒ¨åˆ†ï¼Œè€Œä¸ä¼šæŠ¹å»ä¹‹å‰å·²ç»å®Œæˆçš„è®­ç»ƒè¿›åº¦ã€‚

è¿ç§»å­¦ä¹ ï¼šåœ¨è¿ç§»å­¦ä¹ åœºæ™¯ä¸­ï¼Œå¯èƒ½ä¼šåœ¨é¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šè¿›è¡Œé¢å¤–çš„è®­ç»ƒã€‚ä½¿ç”¨ resume_from_checkpoint å¯ä»¥åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹æƒé‡ï¼Œç„¶ååœ¨æ­¤åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒã€‚


## python è§£åŒ…å­—å…¸
åœ¨Pythonä¸­ï¼Œ`**`ç”¨äºè§£åŒ…å­—å…¸ã€‚åœ¨ä½ æä¾›çš„ä»£ç ç‰‡æ®µä¸­ï¼š

```python
user_prompt = generate_prompt({**data_point, "output": ""})
```

è¿™è¡Œä»£ç æ„å›¾æ˜¯åˆ›å»ºä¸€ä¸ªæ–°çš„å­—å…¸ï¼Œè¿™ä¸ªå­—å…¸é¦–å…ˆæ˜¯é€šè¿‡è§£åŒ…`data_point`å­—å…¸æ¥åˆå§‹åŒ–çš„ï¼Œç„¶ååœ¨è¿™ä¸ªåŸºç¡€ä¸Šæ·»åŠ æˆ–æ›´æ–°ä¸€ä¸ª`"output"`é”®ï¼Œå…¶å€¼è¢«è®¾ç½®ä¸ºä¸€ä¸ªç©ºå­—ç¬¦ä¸²`""`ã€‚

å…·ä½“æ¥è¯´ï¼š

- `data_point`æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«äº†ä¸€äº›é”®å€¼å¯¹ã€‚
- `{**data_point}`éƒ¨åˆ†å°†`data_point`å­—å…¸è§£åŒ…ï¼Œå°†å…¶å†…å®¹æ”¾å…¥åˆ°ä¸€ä¸ªæ–°çš„å­—å…¸ä¸­ã€‚
- `{**data_point, "output": ""}`å°†è¿™ä¸ªæ–°å­—å…¸å’Œä¸€ä¸ªæ–°çš„é”®å€¼å¯¹`"output": ""`åˆå¹¶ï¼Œå½¢æˆä¸€ä¸ªæ–°çš„å­—å…¸ã€‚

å¦‚æœ`data_point`ä¸­å·²ç»åŒ…å«äº†`"output"`è¿™ä¸ªé”®ï¼Œé‚£ä¹ˆåœ¨è¿™ä¸ªæ–°å­—å…¸ä¸­ï¼Œ`"output"`çš„å€¼å°†ä¼šè¢«æ›´æ–°ä¸º`""`ï¼ˆç©ºå­—ç¬¦ä¸²ï¼‰ã€‚å¦‚æœ`"output"`é”®ä¸å­˜åœ¨äº`data_point`ä¸­ï¼Œé‚£ä¹ˆå®ƒå°†è¢«æ·»åŠ åˆ°æ–°å­—å…¸ä¸­ã€‚

è¿™ç§ç”¨æ³•åœ¨Pythonä¸­å¾ˆå¸¸è§ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦åŸºäºç°æœ‰å­—å…¸å¿«é€Ÿåˆ›å»ºæ–°å­—å…¸æ—¶ã€‚åœ¨è¿™ä¸ªä¸Šä¸‹æ–‡ä¸­ï¼Œå®ƒå¯èƒ½ç”¨äºç”Ÿæˆä¸€ä¸ªç”¨äºè®­ç»ƒçš„è¯­è¨€æ¨¡å‹çš„æç¤ºï¼Œå…¶ä¸­`"output"`é”®å¯èƒ½è¢«ç”¨æ¥æ§åˆ¶æ˜¯å¦åœ¨ç”Ÿæˆçš„æç¤ºä¸­åŒ…å«è¾“å‡ºæ–‡æœ¬ã€‚


å­—å…¸è§£åŒ…ï¼ˆDictionary Unpackingï¼‰æ˜¯Pythonä¸­çš„ä¸€ç§è¯­æ³•ç‰¹æ€§ï¼Œå®ƒå…è®¸ä½ åœ¨ä¸€ä¸ªè¡¨è¾¾å¼ä¸­å°†å­—å…¸çš„é”®å€¼å¯¹ç›´æ¥æå–å‡ºæ¥ï¼Œç”¨äºåˆ›å»ºæ–°çš„å­—å…¸æˆ–è€…ä½œä¸ºå‡½æ•°è°ƒç”¨çš„å…³é”®å­—å‚æ•°ã€‚è¿™ç§ç‰¹æ€§åœ¨Python 3.5åŠä»¥åçš„ç‰ˆæœ¬ä¸­å¼•å…¥ã€‚

### å­—å…¸è§£åŒ…çš„ä¸¤ç§å¸¸è§ç”¨æ³•ï¼š

1. **åˆ›å»ºæ–°å­—å…¸æ—¶çš„è§£åŒ…**ï¼š
   å½“ä½ æƒ³è¦åŸºäºå·²æœ‰çš„å­—å…¸åˆ›å»ºä¸€ä¸ªæ–°çš„å­—å…¸ï¼Œå¹¶ä¸”éœ€è¦æ·»åŠ æˆ–ä¿®æ”¹ä¸€äº›é”®å€¼å¯¹æ—¶ï¼Œå¯ä»¥ä½¿ç”¨å­—å…¸è§£åŒ…ã€‚è¿™å¯ä»¥é€šè¿‡åœ¨å­—å…¸åå‰åŠ ä¸Š`**`æ¥å®ç°ã€‚

   ```python
   original_dict = {'a': 1, 'b': 2}
   new_dict = {'c': 3, **original_dict}
   ```

   ä¸Šè¿°ä»£ç ä¸­ï¼Œ`original_dict`çš„å†…å®¹è¢«è§£åŒ…å¹¶æ·»åŠ åˆ°`new_dict`ä¸­ã€‚ç»“æœæ˜¯`new_dict`å˜æˆäº†`{'c': 3, 'a': 1, 'b': 2}`ã€‚

2. **å‡½æ•°è°ƒç”¨æ—¶çš„è§£åŒ…**ï¼š
   å½“è°ƒç”¨å‡½æ•°æ—¶ï¼Œå¦‚æœéœ€è¦å°†å­—å…¸ä¸­çš„é”®å€¼å¯¹ä½œä¸ºå…³é”®å­—å‚æ•°ä¼ é€’ï¼Œå¯ä»¥ä½¿ç”¨å­—å…¸è§£åŒ…ã€‚

   ```python
   def my_function(a, b, c):
       print(a, b, c)

   params = {'b': 2, 'c': 3}
   my_function(a=1, **params)
   ```

   åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œ`params`å­—å…¸ä¸­çš„`'b'`å’Œ`'c'`é”®å€¼å¯¹è¢«è§£åŒ…å¹¶ä½œä¸ºå…³é”®å­—å‚æ•°ä¼ é€’ç»™`my_function`å‡½æ•°ã€‚

### å­—å…¸è§£åŒ…çš„æ³¨æ„äº‹é¡¹ï¼š

- è§£åŒ…çš„å­—å…¸å¿…é¡»æœ‰æœ‰æ•ˆçš„é”®å€¼å¯¹ã€‚
- å¦‚æœåœ¨è§£åŒ…æ—¶ä¸ç›®æ ‡å­—å…¸æˆ–å‡½æ•°è°ƒç”¨ä¸­å­˜åœ¨é‡å¤çš„é”®ï¼Œè§£åŒ…å­—å…¸ä¸­çš„é”®å€¼å¯¹ä¼šè¦†ç›–å·²æœ‰çš„ã€‚
- è§£åŒ…åªèƒ½åœ¨å­—å…¸å­—é¢é‡çš„ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨ï¼Œä¸èƒ½ç”¨äºå…¶ä»–æ•°æ®ç»“æ„ã€‚

å­—å…¸è§£åŒ…æä¾›äº†ä¸€ç§æ–¹ä¾¿çš„æ–¹å¼æ¥æ“ä½œå’Œä¼ é€’å­—å…¸æ•°æ®ï¼Œä½¿å¾—ä»£ç æ›´åŠ ç®€æ´å’Œæ˜“äºé˜…è¯»ã€‚


# æ¨¡å‹ä¸‹è½½
/data/liudaoxuan/Grounding4Rec/qwen/Qwen1___5-0___5B

# llama-7b
https://www.modelscope.cn/models/skyline2006/llama-7b/files

```c++
#æ¨¡å‹ä¸‹è½½
from modelscope import snapshot_download
model_dir = snapshot_download('skyline2006/llama-7b', cache_dir='./')
```
## é€šä¹‰åƒé—®1.5-1.8B

```c++
#æ¨¡å‹ä¸‹è½½
from modelscope import snapshot_download
model_dir = snapshot_download('qwen/Qwen1.5-1.8B', cache_dir='./')
```
## é€šä¹‰åƒé—®1.5-0.5B
```python
#æ¨¡å‹ä¸‹è½½
from modelscope import snapshot_download
model_dir = snapshot_download('qwen/Qwen1.5-0.5B', cache_dir='./')
```

# ä»£ç è¿è¡Œè¿‡ç¨‹
## å¸¸ç”¨æŒ‡ä»¤
![](../img/Pasted%20image%2020240729124524.png)
![](../img/Pasted%20image%2020240729124546.png)


## vscode debug
# vscode å¦‚ä½•debug python torchrun deepspeed

## æœ€ä¼˜é›…çš„æ–¹å¼

### å®‰è£…
1. å®‰è£…åŒ… `pip install debugpy -U`
2. å®‰è£…vscodeå…³äºpythonçš„ç›¸å…³æ’ä»¶
### å†™é…ç½®
ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå¤§å®¶éƒ½æ˜¯ä½¿ç”¨deepspeedã€torchrunè¿è¡Œä»£ç ã€‚å‚æ•°éƒ½ç‰¹åˆ«å¤šï¼Œç„¶åéƒ½æ˜¯ä½¿ç”¨`sh xxxx.sh`å¯åŠ¨è„šæœ¬ã€‚

#### åœ¨pythonä»£ç é‡Œé¢ï¼ˆæœ€å‰é¢åŠ ä¸Šè¿™å¥è¯ï¼‰

```python
import debugpy
try:
    # 5678 is the default attach port in the VS Code debug configurations. Unless a host and port are specified, host defaults to 127.0.0.1
    debugpy.listen(("localhost", 9501))
    print("Waiting for debugger attach")
    debugpy.wait_for_client()
except Exception as e:
    pass

```
#### åœ¨vscodeçš„launch.jsonçš„configurationé‡Œé¢ï¼ŒåŠ ä¸Šè¿™ä¸ªé…ç½®

```json
{
            "name": "sh_file_debug",
            "type": "debugpy",
            "request": "attach",
            "connect": {
                "host": "localhost",
                "port": 9501
            }
        },
```
ğŸš¨ ä¸Šé¢çš„ç«¯å£å·éƒ½å†™ä¸€æ ·ã€‚åˆ«æé”™äº†ã€‚
## å¯åŠ¨

1. å°±æ­£å¸¸å¯åŠ¨ï¼Œç›´æ¥`sh xxx.sh`
2. åœ¨ä½ éœ€è¦debugçš„pythonæ–‡ä»¶ï¼Œæ‰“ä¸Šdebugæ–­ç‚¹ã€‚
2. ä½ çœ‹æ‰“å°å‡ºæ¥çš„ä¸œè¥¿ï¼Œæ˜¯ä¸æ˜¯å‡ºç°`Waiting for debugger attach`.ä¸€èˆ¬æ¥è¯´ï¼Œéƒ½å¾ˆå¿«ï¼Œå°±å‡ºç°äº†ã€‚
3. å†åœ¨vscodeçš„debugé¡µé¢ï¼Œé€‰æ‹©`sh_file_debug`è¿›è¡Œdebugã€‚
4. å°±åŸºæœ¬ä¸Šå®Œæˆäº†ã€‚ç¡®å®æ˜¯å¾ˆæ–¹ä¾¿ã€‚
5. **debugç»“æŸä¹‹åï¼Œåˆ«å¿˜è®°æŠŠä»£ç é‡Œé¢çš„ æ·»åŠ çš„ä»£ç ï¼Œæ³¨é”€æ‰**
## ä½¿ç”¨é•œåƒæº

```python
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple transformers==4.37.0

pip install -i https://pypi.tuna.tsinghua.edu.cn/simple peft==0.3.0
```
## åå°è¿è¡Œç¨‹åº

```python
nohup ./train_qwen.sh >qinwen_18.log 2>&1 &

nohup ./train_qwen.sh >qinwen_05.log 2>&1 &

nohup ./train.sh >llama.log 2>&1 &

nohup ./inference_qwen18.sh >inference_qwen18.log 2>&1 &
nohup ./inference_qwen05.sh >inference_qwen05.log 2>&1 &


nohup ./train_qwen.sh >qinwen_05_13.log 2>&1 &
nohup ./train_qwen14.sh >qinwen_05_14.log 2>&1 &
nohup ./train_qwen55.sh >qinwen_05_55.log 2>&1 &


nohup ./train_qwen.sh >qinwen_05_18.log 2>&1 &

nohup ./inference_tem.sh >inference_tem_5000.log 2>&1 &
nohup ./inference_D3.sh >inference_D3.log 2>&1 &

nohup ./inference_D3m.sh >inference_D3m_2000.log 2>&1 &
nohup ./inference_D3m.sh >inference_D3m_5000.log 2>&1 &
nohup ./inference_tem.sh >inference_tem_1000.log 2>&1 &
nohup ./inference_tem_qwen18.sh >inference_tem_qwen18_5000.log 2>&1 &


python ./evaluate.py --input_dir ./book_result


nohup ./inference_D3m.sh >inference_D3m.log 2>&1 &
```

## Preprocess
æŒ‰ç…§æ­¥éª¤è¿›è¡Œå¤„ç†å³å¯
```python
python process.py gao --category "Book" --metadata ./path_to_metadata.json --reviews ./path_to_reviews.json --K 5 --st_year 2017 --st_month 10 --ed_year 2018 --ed_month 11 --output True

python process.py --category="Books"
nohup python process.py --category="Books" >inf_qwen18.log 2>&1 &
```
2024-07-30 19:55:56.045 | INFO     | __main__:gao:172 - interaction_list: 853747
2024-07-30 19:56:20.036 | INFO     | __main__:gao:196 - Train Books: 682997
2024-07-30 19:56:20.042 | INFO     | __main__:gao:197 - Valid Books: 85375
2024-07-30 19:56:20.048 | INFO     | __main__:gao:198 - Test Books: 85375
2024-07-30 19:56:20.050 | INFO     | __main__:gao:199 - Done!
https://huggingface.co/blog/zh/constrained-beam-search

# Grounding4Rec

For item embedding, due to the quota of the git LFS, you can use the [link](https://rec.ustc.edu.cn/share/78de1e20-763a-11ee-b439-a3ef6ed8b1a3) with password 0g1g.
### Environment
```
pip install -r requirements.txt
```

```python
pip install -b /data/liudaoxuan/tmp 
```

```python
pip config set global.cache-dir "/data/liudaoxuan/pip_cache"
```
### Preprocess
Please follow the process.ipynb in each data directory.
### Training on Single Domain
```
Grounding4Rec/skyline2006/llama-7b
for seed in 0 1 2
do
    for lr in 1e-4
    do
        for dropout in 0.05    
        do
            for sample in 1024
            do
                echo "lr: $lr, dropout: $dropout , seed: $seed,"
                CUDA_VISIBLE_DEVICES=$1 python train.py \
                    --base_model "[\"./skyline2006/llama-7b\"]" \
                    --train_data_path "[\"./data/movie/train.json\"]"   \
                    --val_data_path "[\"./data/movie/valid_5000.json"]" \
                    --output_dir /model/movie/${seed}_${sample} \
                    --batch_size 128 \
                    --micro_batch_size 4 \
                    --num_epochs 50 \
                    --learning_rate $lr \
                    --cutoff_len 512 \
                    --lora_r 8 \
                    --lora_alpha 16\
                    --lora_dropout $dropout \
                    --lora_target_modules '[q_proj,v_proj]' \
                    --train_on_inputs \
                    --group_by_length \
                    --resume_from_checkpoint 'XXX' \
                    --seed $seed \
                    --sample $sample 
            done    
        done
    done
done
```
### Training on Multi Domain
```
for seed in 0 1 2
do
    for lr in 1e-4
    do
        for dropout in 0.05    
        do
            for sample in 1024
            do
                echo "lr: $lr, dropout: $dropout , seed: $seed,"
                CUDA_VISIBLE_DEVICES=$1 python train.py \
                    --base_model YOUR_LLAMA_PATH/ \
--train_data_path "[\"./data/movie/train.json\", \"./data/game/train.json\"]"  \
                    --val_data_path "[\"./data/movie/valid_5000.json\", \"./data/game/valid_5000.json\"]"  \
                    --output_dir ./model/multi/${seed}_${sample} \
                    --batch_size 128 \
                    --micro_batch_size 4 \
                    --num_epochs 50 \
                    --learning_rate $lr \
                    --cutoff_len 512 \
                    --lora_r 8 \
                    --lora_alpha 16\
                    --lora_dropout $dropout \
                    --lora_target_modules '[q_proj,v_proj]' \
                    --train_on_inputs \
                    --group_by_length \
                    --resume_from_checkpoint 'XXX' \
                    --seed $seed \
                    --sample $sample 
            done    
        done
    done
done
                    
```

### Training on Multiple GPU Card
We provide our accelerate config in ./config/accelerate.yaml
```
accelerate config # Please set up your config
for seed in 0 1 2
do
    for lr in 1e-4
    do
        for dropout in 0.05    
        do
            for sample in 1024
            do
                echo "lr: $lr, dropout: $dropout , seed: $seed,"
                CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch train.py \
                    --base_model YOUR_LLAMA_PATH/ \
--train_data_path "[\"./data/movie/train.json\", \"./data/game/train.json\"]"  \
                    --val_data_path "[\"./data/movie/valid_5000.json\", \"./data/game/valid_5000.json\"]"  \
                    --output_dir ./model/multi/${seed}_${sample} \
                    --batch_size 128 \
                    --micro_batch_size 4 \
                    --num_epochs 50 \
                    --learning_rate $lr \
                    --cutoff_len 512 \
                    --lora_r 8 \
                    --lora_alpha 16\
                    --lora_dropout $dropout \
                    --lora_target_modules '[q_proj,v_proj]' \
                    --train_on_inputs \
                    --group_by_length \
                    --resume_from_checkpoint 'XXX' \
                    --seed $seed \
                    --sample $sample 
            done    
        done
    done
done
```

### Inference
```
#  Taking movie as an example
python inference.py \
    --base_model YOUR_LLAMA_PATH/ \
    --lora_weights YOUR_LORA_PATH \
    --test_data_path ./data/movie/test/test_5000.json \
    --result_json_data ./movie_result/movie.json
```

### Evaluate
```
# Taking Movie as an example
# Directly
python ./evaluate.py --input_dir ./book_result

 
# CI Augmented
python ./data/movie/adjust_ci.py --input_dir ./movie_result # Note that you need to have your own SASRec/DROS model (Specify the path in the code)
```

è®ºæ–‡ä¸­ä¹Ÿæ²¡è¯´å…·ä½“æ€ä¹ˆå®ç°ä¿è¯ç”Ÿæˆçš„item æ˜¯

![](../img/Pasted%20image%2020240731200447.png)

# transformers çŸ¥è¯†ç‚¹
åœ¨`transformers`åº“ä¸­ï¼Œ`tokenizer`æ˜¯æ–‡æœ¬å¤„ç†çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå®ƒè´Ÿè´£å°†åŸå§‹æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ ¼å¼ï¼ˆå¦‚token IDsï¼‰ï¼Œå¹¶è¿›è¡Œè§£ç ä»¥å°†ç”Ÿæˆçš„token IDsè½¬æ¢å›æ–‡æœ¬ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸ç”¨çš„`tokenizer`æ“ä½œï¼š

## tokenizer
1. **åˆå§‹åŒ–Tokenizer**:
   - åŠ è½½é¢„è®­ç»ƒæ¨¡å‹çš„tokenizerã€‚
     ```python
     from transformers import AutoTokenizer
     tokenizer = AutoTokenizer.from_pretrained("model_name")
     ```

2. **ç¼–ç æ–‡æœ¬ï¼ˆEncodingï¼‰**:
   - å°†æ–‡æœ¬è½¬æ¢ä¸ºtoken IDsã€‚
     ```python
     input_ids = tokenizer.encode("Hello, world!", return_tensors="pt")
     ```

3. **è§£ç Token IDsï¼ˆDecodingï¼‰**:
   - å°†token IDsè½¬æ¢å›æ–‡æœ¬ã€‚
     ```python
     decoded_text = tokenizer.decode(input_ids, skip_special_tokens=True)
     ```

4. **ç‰¹æ®ŠTokenå¤„ç†**:
   - è·å–æˆ–è®¾ç½®ç‰¹æ®Štokenï¼Œå¦‚`[PAD]`ã€`[CLS]`ã€`[SEP]`ç­‰ã€‚
     ```python
     tokenizer.pad_token = '[PAD]'
     tokenizer.cls_token = '[CLS]'
     tokenizer.sep_token = '[SEP]'
     ```

5. **æ‰¹é‡ç¼–ç ï¼ˆBatch Encodingï¼‰**:
   - åŒæ—¶å¯¹å¤šæ¡æ–‡æœ¬è¿›è¡Œç¼–ç ã€‚
     ```python
     inputs = ["Hello, world!", "Transformers are amazing!"]
     batch_input_ids = tokenizer(inputs, return_tensors="pt", padding=True)
     ```

6. **å¡«å……ï¼ˆPaddingï¼‰å’Œè£å‰ªï¼ˆTruncationï¼‰**:
   - å¯¹æ–‡æœ¬åºåˆ—è¿›è¡Œå¡«å……æˆ–è£å‰ªä»¥æ»¡è¶³æ¨¡å‹çš„è¾“å…¥è¦æ±‚ã€‚
     ```python
     padded_input_ids = tokenizer.encode("Hello", return_tensors="pt", padding='longest')
     truncated_input_ids = tokenizer.encode("Hello, this is a very long sentence that will be truncated", return_tensors="pt", truncation=True)
     ```

7. **è®¾ç½®å¡«å……å’Œè£å‰ªå‚æ•°**:
   - é…ç½®å¡«å……å’Œè£å‰ªçš„è¡Œä¸ºï¼Œå¦‚æœ€å¤§é•¿åº¦ã€æ–¹æ³•ç­‰ã€‚
     ```python
     tokenizer.padding_side = "right"
     tokenizer.max_length = 512
     tokenizer.truncation_side = "right"
     ```

8. **è·å–è¯æ±‡è¡¨å¤§å°ï¼ˆVocabulary Sizeï¼‰**:
   - è·å–tokenizerçš„è¯æ±‡è¡¨å¤§å°ã€‚
     ```python
     vocab_size = tokenizer.vocab_size
     ```

9. **ä¿å­˜Tokenizer**:
   - å°†tokenizerä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿã€‚
     ```python
     tokenizer.save_pretrained("path_to_save_tokenizer")
     ```

10. **åŠ è½½Tokenizer**:
    - ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½tokenizerã€‚
    ```python
    tokenizer = AutoTokenizer.from_pretrained("path_to_tokenizer")
    ```

11. **è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥**:
    - å°†ç¼–ç åçš„æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹çš„è¾“å…¥æ ¼å¼ã€‚
     ```python
     inputs = {
         "input_ids": batch_input_ids,
         "attention_mask": batch_attention_mask,  # é€šå¸¸ä¸input_idsä¸€èµ·ç”Ÿæˆ
     }
     ```

12. **ä½¿ç”¨ä¸åŒçš„è§£ç ç­–ç•¥**:
    - ä½¿ç”¨ä¸åŒçš„è§£ç æ–¹æ³•ï¼Œå¦‚è´ªå©ªè§£ç ã€æŸæœç´¢ï¼ˆBeam Searchï¼‰ç­‰ã€‚
     ```python
     generated_text = tokenizer.decode(input_ids, skip_special_tokens=True)
     ```

13. **å¤„ç†å¤šè¯­è¨€æ–‡æœ¬**:
    - å¯¹äºæ”¯æŒå¤šè¯­è¨€çš„tokenizerï¼Œå¯ä»¥å¤„ç†ä¸åŒè¯­è¨€çš„æ–‡æœ¬ã€‚
     ```python
     tokenizer = AutoTokenizer.from_pretrained("multilingual_model_name")
     ```

14. **è·å–Tokenä¿¡æ¯**:
    - è·å–ç‰¹å®štokençš„ä¿¡æ¯ï¼Œå¦‚IDæˆ–æ–‡æœ¬ã€‚
     ```python
     token_id = tokenizer.convert_tokens_to_ids("[CLS]")
     token_text = tokenizer.convert_ids_to_tokens(token_id)
     ```

è¿™äº›æ“ä½œä¸ºä½¿ç”¨`transformers`åº“è¿›è¡ŒNLPä»»åŠ¡æä¾›äº†å¼ºå¤§çš„æ–‡æœ¬å¤„ç†èƒ½åŠ›ï¼Œç¡®ä¿æ–‡æœ¬æ•°æ®å¯ä»¥æœ‰æ•ˆåœ°è¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Œå¹¶ä»æ¨¡å‹è¾“å‡ºä¸­å¾—åˆ°æœ‰æ„ä¹‰çš„æ–‡æœ¬ç»“æœã€‚


