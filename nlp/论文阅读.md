## kNN-BOX
 A Unified Framework for Nearest Neighbor Generation
将数据增强的过程分解为三个模块
kNN-BOX decomposes the datastore-augmentation approach into three modules: `datastore, retriever and combiner`, thus putting diverse kNN generation methods into a unified way.

### kNN-MT （Nearest Neighbor Machine Translation）
即使用kNN算法在大规模的预处理数据上做检索，搜寻最相似的k条数据来辅助翻译模型的生成。
方法简介：
作者的算法分为两个步骤，同时还需要一个`预训练好的 MT 神经网络模型`（下面简称预训练模型，记作 f）来帮助表征文本，具体做法如下
- 数据存储：作者把原始数据处理成特殊的 key-value 对的形式。其中 key 为被预训练模型表征的源语句 + 目标语句的前缀，一般使用预训练模型 decoder 最后一层隐藏层向量作为 <源语句，目标语句前缀> 表征；value 则为目标语句前缀的下一个单词。
举个例子，对于 "I love you -> 我爱你" 的英中语对，我们可以按照中文侧汉字的顺序构建多组 key-value 对，每组分别是：
a. key=f(<I love you, BOS> )， value = 我
其中 BOS 代表 Begin of Sentence，
f(<x,y>) 代表预训练模型输入 x 和 y 作为源语句和目标语句时，预训练模型 decoder 最后一层的隐藏层向量

b. key=f(<I love you, BOS 我> )， value = 爱

c. key=f(<I love you, BOS 我爱> )， value = 你

d. key=f(<I love you, BOS 我爱你> )， value=EOS
 其中 EOS 代表 End of Sentence

- 文本生成：做翻译时，我们也用类似的方法可以得到 f(<源语句，目标语句前缀>) 的表征，我们这里记作 query，此时，这可以通过 kNN 算法去查找上一步构建 key-value 对的中最邻近 k 个的表征向量 key，并将其 value 作为候选单词。作者提出根据 key 和 query 的距离作为权重，来规整 value 的概率：
最终的生成新词概率分布为 kNN 概率与预训练模型新词的概率的线性插值：

## Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation

### Span Meta-evaluation
“Span Meta-evaluation” 是一种评估机器翻译系统性能的方法，它结合了不同的评估模式，以更全面的方式评估翻译质量。这种方法通常涉及以下几个步骤：
1. **翻译质量评估**：
   - 在不同的评估模式下（T、S-T、R-T、S-R-T），使用自动评估指标（如BLEU、TER等）或人工评估方法（人工评分、人工比较等）对机器翻译系统的性能进行评估。
2. **跨度（Span）定义**：
   - 定义一些特定的跨度（Span），比如句子、短语或词组。这些跨度通常是与语言结构相关的，比如短语边界或句子边界。
3. **跨度级别的评估**：
   - 在不同的评估模式下，评估翻译系统在定义的跨度上的性能。这包括对跨度的准确性、流畅度和翻译质量进行评估。
4. **汇总结果**：
   - 将不同评估模式下的跨度级别评估结果进行汇总，以得出对机器翻译系统整体性能的综合评估。
   Span Meta-evaluation 的优势在于它能够提供对翻译系统性能的更全面、更细粒度的评估。通过考虑不同跨度级别上的翻译质量，评估者可以更准确地了解系统的优点和缺陷，并指导系统的改进和优化。

### Category Meta-evaluation

“Category Meta-evaluation” 是一种评估机器翻译系统性能的方法，它基于不同的翻译类别进行评估，以便更全面地了解翻译系统的性能。
这种方法通常涉及以下几个步骤：
1. **定义翻译类别**：
   - 定义一系列不同的翻译类别，这些类别可以是语言结构的不同层次，比如句子、短语、单词，也可以是不同主题、领域或语体。
2. **翻译质量评估**：
   - 在每个翻译类别下，使用自动评估指标（如BLEU、TER等）或人工评估方法（人工评分、人工比较等）对机器翻译系统的性能进行评估。
3. **汇总结果**：
   - 将不同翻译类别下的评估结果进行汇总，以得出对机器翻译系统整体性能的综合评估。
   通过 Category Meta-evaluation，评估者可以更全面地了解机器翻译系统在不同类别下的表现。这有助于发现系统在特定类别下的优势和劣势，并指导系统的改进和优化。

### 机器翻译中几种不同的评估模式
在机器翻译中，有几种不同的模式用于评估翻译系统的性能和质量：
1. **Translation-only (T) 模式**：
   - 在这种模式下，只有机器翻译的输出被评估，而不考虑源语言文本或参考翻译。
   - 这种模式下的评估通常基于自动评估指标，比如 BLEU、TER 等。
2. **Source-Translation (S-T) 模式**：
   - 这种模式下，机器翻译的输出和原始输入文本被一起评估。
   - 评估者会将机器翻译的输出与原始输入文本进行比较，来评估翻译的准确性和流畅度。
3. **Reference-Translation (R-T) 模式**：
   - 在这种模式下，机器翻译的输出和参考翻译之间进行比较。
   - 评估者会将机器翻译的输出与人工提供的参考翻译进行比较，来评估机器翻译系统的质量。
4. **Source-Reference-Translation (S-R-T) 模式**：
   - 这种模式结合了 S-T 和 R-T 两种模式的特点，同时考虑了源语言文本、参考翻译和机器翻译的输出。
   - 评估者会将机器翻译的输出与原始输入文本以及参考翻译进行比较，综合考虑翻译的准确性、流畅度和质量。
### 目的

This study aims to explore how LLMs leverage source and reference information in evaluating translations, with the ultimate goal of better understanding the working mechanism of LLMs.
coarse-grained：粗粒度的
元评估（Meta-evaluation）是评估评估方法和过程的评估。


论文发现 reference 信息显著提高了评估的准确性，而源信息有时会适得其反，这表明在使用llm评估翻译时缺乏跨语言能力。
这些发现也为llm提供了一个`潜在的研究方向`，即充分利用llm的跨语言能力，在机器翻译评估任务中实现更好的性能。

我们令人惊讶地发现，参考信息显著提高了系统级的准确性和段级的相关性，而源信息有时会适得其反。
![](../img/Pasted%20image%2020240421192533.png)
这些观察结果表明，尽管ChatGPT在多语言或翻译任务中表现显著，但在使用llm评估翻译句子时缺乏跨语言能力。




## 学术报告-大语言模型的多语言理解能力探究-黄书剑-南京大学自然语言处理研究组（南大NLP）

![](../img/Pasted%20image%2020240420234009.png)
![](../img/Pasted%20image%2020240421155544.png)

![](../img/Pasted%20image%2020240421154503.png)
结果分析
![](../img/Pasted%20image%2020240421155503.png)

总结：
### 基于 In-context Learning 的机器翻译
1. 通过 In-context Learning 使用大语言模型进行机器翻译，再对翻译结果以及翻译的效果进行评估。
### 如何通过ICL 展示翻译能力
3. 对于ICL 为什么能够提高大语言模型翻译能力进行了分析。
   - 不同翻译模版的效果分析
   - 不同翻译示例对于效果的影响
   ![](../img/Pasted%20image%2020240421160753.png)
### 基于指令微调的机器翻译
3. 对翻译能力的潜力研究(潜力是否能够发挥出来)
   - 显示的要求模型完成翻译指令（通过指令学习(微调)）
   ![](../img/Pasted%20image%2020240421161449.png)

### 通过指令微调展示翻译能力原因
4. 探究指令学习为什么能够提升翻译的质量。
   - 可能提高了语言翻译中的直接联系（指令学习前和指令学习后使用英文作为pivot的翻译效果差异减小）
   ![](../img/Pasted%20image%2020240421162140.png)
   ![](../img/Pasted%20image%2020240421162727.png)
### 语言能力的多语言扩展
5. 语言能力的扩展，有一个llm 如何对不同语言的翻译进行服务
   - 中文+ 多语言继续预训练
   ![](../img/Pasted%20image%2020240421163228.png)
   - 思想通过建立语言对其进行新语言内容的学习。
     ![](../img/Pasted%20image%2020240421163411.png)
      ![](../img/Pasted%20image%2020240421163631.png)

![](../img/Pasted%20image%2020240421164748.png)
### 总结
![](../img/Pasted%20image%2020240421164828.png)

## Multi-Candidate Speculative Decoding

### Speculative Decoding
投机采样是一种可以从根本上解码计算访存比的方法，`保证和使用原始模型的采样分布完全相同`。它使用两个模型：一个是原始目标模型，另一个是比原始模型小得多的近似模型。`近似模型用于进行自回归串行采样，而大型模型则用于评估采样结果`。解码过程中，某些token的解码相对容易，某些token的解码则很困难。因此，简单的token生成可以交给小型模型处理，而困难的token则交给大型模型处理。这里的小型模型可以采用与原始模型相同的结构，但参数更少，或者干脆使用n-gram模型。小型模型不仅计算量较小，更重要的是减少了内存访问的需求。
https://zhuanlan.zhihu.com/p/651359908

### background

随着大型语言模型（LLMs）在各种NLP任务中展现出强大的能力，其自回归地生成文本时的耗时问题也日益凸显。
加快它们速度的一种方法是推测解码，它从一个快速草稿模型中生成候选片段（一个令牌序列），然后由目标模型并行验证。这种方法在提高大型自回归模型的端到端延迟方面非常有效，但候选令牌的接受率受到多种因素的限制，包括模型、数据集和解码设置。

### method
本文提出从一个 draft 模型中抽取多个候选模型，然后分批组织它们进行验证。即通过生成多个候选令牌，而非仅仅一个，大大增加了接受率，从而在不牺牲准确性的前提下，显著提高了文本生成的速度。


具体来说，Multi-Candidate Speculative Decoding算法的核心思想是在每个解码步骤中生成多个候选令牌，并通过一个评估函数对这些候选令牌进行评估。评估函数基于模型的`置信度、历史令牌的质量等因素`，为每个候选令牌打分。然后，算法选择得分最高的令牌作为当前步骤的输出，并将其作为下一个步骤的输入。


## 优点

这种方法的优点在于，它充分利用了大型语言模型的能力，`通过并行验证多个候选令牌，提高了生成文本的速度`。同时，由于评估函数的引入，算法能够在保持高准确性的同时，动态调整候选令牌的数量和质量，以适应不同的任务和场景。

在实际应用中，Multi-Candidate Speculative Decoding 算法可以广泛应用于各种NLP任务，如机器翻译、文本摘要、对话生成等。通过使用该算法，我们可以显著提高AI文本生成的速度，为用户提供更加流畅、高效的交互体验。




## MAPO: Advancing Multilingual Reasoning through Multilingual-Alignment-as-Preference Optimization

### background
虽然推理能力被认为是与语言无关的，但现有的llm在不同语言中表现出不一致的推理能力，例如，由于多语言训练数据的不平衡，使用英语等主导语言的推理能力优于其他语言。

为了提高非主导语言中的推理能力，我们提出了一个多语言对齐即偏好优化框架（MAPO），旨在将其他语言中的推理过程与主导语言对齐。

具体来说，我们利用一个现成的翻译模型来确定非主导语言和主导语言的答案之间的一致性。我们将其作为优化，例如，直接偏好优化（DPO）或近端策略优化（PPO）的偏好。

### method

#### Preference Estimation

在Preference Estimation过程中，从主导语言和非主导语言的LLM中采样对同一问题的推理过程。采用一个训练有素的现成的翻译模型来产生主导语言和非主导语言的推理之间的翻译概率。

#### Preference Optimization
在偏好优化过程中，采用Proximal Policy Optimization（Schulman等，2017，PPO）和Direct Preference Optimization（Rafailov等，2023，DPO）来优化先前估计的偏好。此外作者还进行了迭代DPO来进行进一步的偏好优化。


## Question Translation Training for Better Multilingual Reasoning

### background
大型语言模型在理推任务上表现出令人信服的表现，但它们在除英语以外的语言中的表现往往要差得多。
### methods
在本文中，我们探讨了question alignment 的好处。

其中我们通过微调  `x-English` 并行问题数据来训练模型将`推理问题翻译为英语`。
通过这种方式，实现了目标语言对齐，从而充分利用英语指令数据来解锁llm的多语言推理能力。

在问题对齐之后，我们通过使用英语指令数据进一步微调与语言对齐的LLM来实现 响应对齐。

## MT-PATCHER: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation


### background
大型语言模型（LLM）已在机器翻译（MT）领域展现出其强大的能力，但却存在计算成本高和延迟的问题。因此，将大型语言模型中的翻译知识转移到中型机器翻译模型中是一个很有前景的研究方向。
然而，传统的知识提炼方法并没有考虑到学生和教师模型的能力，因此重复教授学生模型已学过的知识，而无法扩展到新的语境和知识。

### method
在本文中，我们提出了一个名为 MT-Patcher 的框架，它能有`选择地、全面地、主动地` 将知识从 LLM 转移到现有的 MT 模型中。
考虑到学生 MT 模型当前的翻译能力，我们只对其翻译错误进行识别和纠正，而不是从教师那里提炼整个翻译。




https://zhuanlan.zhihu.com/p/688544065
## EDT: Improving Large Language Models’ Generation by Entropy-basedDynamic Temperature Sampling


### temperature 值

在大模型推理中，temperature 值是一个用于控制生成文本多样性的参数。它通常用于 softmax 函数，用来调节模型输出的概率分布的“平滑程度”。较高的 temperature 值会增加模型生成的多样性，而较低的值则会减少多样性。

- 当 temperature 值接近零时，模型会倾向于生成概率最高的单词，这样生成的文本会更加保守和重复性高。
- 当 temperature 值较高时，模型会生成更多不同的单词，因此生成的文本会更加多样化。

一般来说，合适的 temperature 值取决于特定的应用场景和模型架构，需要通过实验和调整来确定。通常，较常用的 temperature 值范围在0.7到1.0之间。


### background

以前我们总是对一个模型的一次推理设置一个固定的temperature值来调节logits的概率分布，这在大多数情况下能完成任务，但是显然并不是最优的。论文提出基于熵来动态调整temperature值，在解码质量与多样性之间取得了更好的权衡。


# 感想

通过相关论文的阅读，以及一些相关的学术报告，我发现老师最近的工作主要专注于大模型在多语言推理，机器翻译等方面的运用与改进。
感受到大模型的出现对这些传统的nlp的任务确实有了很大的改进，大型语言模型的出现使得NLP任务的处理变得更加简单高效(和传统的方法相比往往使用较小的数据量就能达到一个还不错的效果)，同时也取得了更好的效果，推动了整个NLP领域的发展和进步。
但大模型的可解释性以及知识迁移方面确实还面临着很大的问题，很多时候对这些任务改进的方法，更多的都是来自于直觉，而没有理论方面的支持, 可能很多时候着也是深度学习的通病吧。 





通过阅读相关论文和学术报告，我发现老师最近的工作主要集中在大语言模型在多语言推理和机器翻译等方面的研究上。我深知作为本科生，我对这些领域的理解还有待提高，但我主要想从以下几个方面谈谈我的理解：
### 对老师最近的一些工作的理解。

1. 我发现老师的很多工作都十分具有创新性和开创性。如[Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation] 在llm评估机器翻译时, 发现reference 信息显著提高了评估的准确性，而source信息有时会适得其反，从而表明在使用llm评估翻译时缺乏跨语言能力。也为llm提供了一个潜在的研究方向，即充分利用llm的跨语言能力，在机器翻译评估任务中实现更好的性能。我觉得这种研究是十分有意义的，这种研究往往会引出很多的思考(eg. 在nlp中其它的一些任务中是否有类似的现象 。以及否能通过一些方法，使llm评估时能够充分利用到source 信息等。）。这种具有开创性的任务，正如文章中提到的，能够为llm提供了一个潜在的研究方向，可能以后也会有更多学者参与到充分利用和提升llm跨语言能力上。
2. 我觉得南大nlp组的很多工作是具有开源，贡献精神的。如knn-box 框架为k近邻生成提供了统一的框架，这位很多研究者提供了方便。因为我现在进行的研究是关于一些代表性推荐系统的，我现在做的实验就是基于人大推出的[Recbole] 框架，我是这种学术开源框架的受益者。
3. 我发现老师对大模型及其应用都有研究。如[Multi-Candidate Speculative Decoding] 在原有的Speculative Decoding 方法上进行改进，从而对大模型解码速度以及准确率都有了较高的提升。[Question Translation Training for Better Multilingual Reasoning] [MAPO: Advancing Multilingual Reasoning through Multilingual-Alignment-as-Preference Optimization]都基于英语等主导语言的推理能力优于其他语言这一现象，分别使用了不同的方法，提升了非主导语言的推理效果。

## 对自然语言处理（NLP）领域的理解

1. 自然语言处理（NLP）技术已经深入到我们生活的各个方面，对我们的日常生活产生了重要影响。首先机器翻译系统（如Google翻译、百度翻译等）利用NLP技术实现不同语言之间的自动翻译，帮助我们跨越语言障碍。此外，大语言模型如chatgpt出现，极大地改变了我们的信息获取、交流和应用方式，为我们的生活和工作带来了巨大的便利，现在也成为了我们日常生活中不可或缺的一部分。
2. 我本科接触的是推荐系统方面的研究。在阅读论文时发现，很多推荐系统重特别有代表性的算法模型，利用的很多知识都是从nlp领域迁移过来的，当nlp领域有了一些较大的突破，往往推荐领域也会出现一些有代表性的模型，如 Tranformer 出来以后 SASRec 也出来了，Bert 出来以后, BERT4Rec 也出来了。当然目前nlp领域的很多知识也被迁移到了CV等领域。


## 对于大语言模型对机器翻译等NLP传统任务范式改变的理解。

1. 大模型的出现对这些传统的nlp的任务确实有了很大的改进，大型语言模型的出现使得NLP任务的处理变得更加简单高效(和传统的方法相比往往使用较小的数据量就能达到一个还不错的效果)，同时也取得了更好的效果，推动了整个NLP领域的发展和进步。
2. 但大型语言模型需要大量的计算资源进行训练和推理，包括高性能的计算设备和大规模的训练数据。这使得只有少数大型科技公司或研究机构能够承担建立和维护大型语言模型的成本，限制了模型的普及和应用范围(我们学校就没有这么多资源进行大模型相关的)。推动了NLP领域的发展和进步, 但同时也提高了nlp领域的壁垒，提高了进行nlp研究的开销。
3. 大型语言模型的训练数据往往存在样本偏差，可能导致模型在某些特定领域或群体中表现不佳。并且大型语言模型通常是黑盒模型，难以解释模型的决策过程和内部机制。很多时候对这些任务改进的方法，更多的都是来自于直觉，而没有理论方面的支持, 这可能也是深度学习的通病吧。 




通过阅读相关论文和学术报告，我发现老师最近的工作主要集中在大型语言模型在多语言推理和机器翻译等方面的研究上。我深知作为本科生，我对这些领域的理解还有待提高，但我主要想从以下几个方面谈谈我的理解：

### 对老师最近的一些工作的理解

1. 我发现老师的很多工作都十分具有创新性和开创性。例如，论文《Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation》发现在使用大型语言模型评估机器翻译时，参考信息显著提高了评估的准确性，而源语言信息有时会适得其反，从而表明在使用大型语言模型评估翻译时缺乏跨语言能力。这为大型语言模型提供了一个潜在的研究方向，即充分利用其跨语言能力，在机器翻译评估任务中实现更好的性能。我觉得这种研究是十分有意义的，往往会引出很多的思考，比如在NLP的其他任务中是否有类似的现象，以及是否能通过一些方法，使大型语言模型评估时能够充分利用到源语言信息等。这种具有开创性的任务为大型语言模型提供了一个潜在的研究方向，可能会吸引更多的学者参与到充分利用和提升大型语言模型跨语言能力的研究中。
2. 我觉得南大NLP组的很多工作都具有开源和贡献精神。例如，KNN-Box 框架为K近邻生成提供了统一的框架，为很多研究者提供了方便。因为我现在进行的研究是关于一些代表性推荐系统的，我现在做的实验就是基于中国人民大学Al-Box组推出的 RecBole 框架，我是这种学术开源框架的受益者，所以很敬佩像南大nlp组这样的实验室。
3. 我发现老师对大模型研究很广有但不限于机器翻译方面。例如，论文《Multi-Candidate Speculative Decoding》在原有的 Speculative Decoding 方法上进行改进，从而对大型模型的解码速度和准确率都有了较高的提升。《Question Translation Training for Better Multilingual Reasoning》和《MAPO: Advancing Multilingual Reasoning through Multilingual-Alignment-as-Preference Optimization》都基于英语等主导语言的推理能力优于其他语言这一现象，分别使用了不同的方法，提升了非主导语言的推理效果。《EDT: Improving Large Language Models’ Generation by Entropy-based Dynamic Temperature Sampling》提出基于熵来动态调整temperature值，使大模型在解码质量与多样性之间取得了更好的权衡。

### 对自然语言处理（NLP）领域的理解

1. 自然语言处理（NLP）技术已经深入到我们生活的各个方面，对我们的日常生活产生了重要影响。例如，机器翻译系统（如Google翻译、百度翻译等）利用NLP技术实现不同语言之间的自动翻译，帮助我们跨越语言障碍。此外，大型语言模型如ChatGPT的出现，极大地改变了我们的信息获取、交流和应用方式，为我们的生活和工作带来了巨大的便利，现在也成为了我们日常生活中不可或缺的一部分。

2. 我本科接触的是推荐系统方面的研究。在阅读论文时发现，很多推荐系统采用的算法模型都是从NLP领域迁移过来的。当NLP领域取得一些突破时，推荐领域往往也会出现一些有代表性的模型，例如 Transformer 出现后，SASRec 模型也随之出现，BERT 出现后，BERT4Rec 模型也相继问世。我觉得，nlp 领域往往是走在技术的最前端的，nlp领域的进步往往也会推进其它领域的进步，这也是我希望选择nlp作为研究生研究方向的主要原因。

### 对于大型语言模型对机器翻译等NLP传统任务范式改变的理解

1. 大型语言模型的出现对这些传统的NLP任务确实带来了很大的改进，使得NLP任务的处理变得更加简单高效。与传统方法相比，大型语言模型通常能够在使用较小的数据量时达到更好的效果，同时也取得了更好的效果，推动了整个NLP领域的发展和进步。
2. 但大型语言模型需要大量的计算资源进行训练和推理，包括高性能的计算设备和大规模的训练数据。这使得只有少数大型科技公司或研究机构能够承担建立和维护大型语言模型的成本，限制了模型的普及和应用范围。这一方面推动了NLP领域的发展和进步，但同时也提高了进行NLP研究的门槛和开销。
3. 大型语言模型的训练数据往往存在样本偏差，可能导致模型在某些特定领域或群体中表现不佳。此外，大型语言模型通常是黑盒模型，难以解释模型的决策过程和内部机制。很多时候对这些任务改进的方法更多地是来自于直觉，而没有理论方面的支持，这可能也是深度学习的通病。



# 问题回答




